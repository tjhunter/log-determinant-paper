
\section{Ultra-sparsifiers as determinant preconditioners}


\subsection{Reduction on a Laplacian}

\label{sec:Making-the-problem}

From now on, we consider the computation of $\log A$, where $A\in SDD_{n}$.
The techniques we will develop work on Laplacian matrices instead
of SDD matrices. An SDD matrix is positive semi-definite while a Laplacian
matrix is always singular, since its nullspace is spanned by $\mathbf{1}$.
We generalize the definition of the determinant to handle this technicality. 
\begin{definition}
\emph{Pseudo-log-determinant (PLD):} Let $A\in\mathcal{S}^{n+}$ be
a non-null positive semi-definite matrix. The pseudo-log-determinant
is defined by the sum of the logarithms of all the positive eigenvalues:
\[
\ld\left(A\right)=\sum_{\lambda_{i}>0}\log\left(\lambda_{i}\right)
\]
where $\lambda_{i}$ are the eigenvalues of $A$. 
\end{definition}

The interest of the PLD lies in the connection between SDD matrices
and some associated Laplacian. It is well-known that solving an SDD
system in $SDD_{n}$ can be reduced to solving a Laplacian system
of size $2n+1$, using the reduction technique introduced Gremban
in \cite{Gremban1996}. Recall that a Laplacian has all its non-diagonal
terms non-positive, the sum of each row and each column being zero.
The reduction has been simplified by Kelner et al. in \cite{kelner2013simple},
Appendix A. Using the Kelner et al.\ reduction, we can turn the computation
of a the log-determinant of a SDD system into the computation of two
PLDs of Laplacians, as shown in the next lemma. 
\begin{lemma}
\emph{Kelner et al.\ reduction for log-determinants. }Given an invertible
SDD matrix $A$, consider the Kelner decomposition $A=D_{1}+A_{p}+A_{n}+D_{2}$
where: 
\begin{itemize}
\item $A_{p}$ is the matrix that contains all the positive off-diagonal
terms of $A$ 
\item $A_{n}$is the matrix that contains all the negative off-diagonal
terms of $A$ 
\item $D_{1}$ is a diagonal matrix that verifies $D_{1}\left(i,i\right)=\sum_{j\neq i}\left|A\left(i,j\right)\right|$ 
\item $D_{2}$ is the excess diagonal matrix: $D_{2}=A-A_{p}-A_{n}-D_{1}$ 
\end{itemize}
Call $\hat{A}=D_{1}+A_{n}-A_{p}$ and $\tilde{A}=\left(\begin{array}{cc}
D_{1}+D_{2}/2+A_{n} & -D_{2}/2-A_{p}\\
-D_{2}/2-A_{p} & D_{1}+D_{2}/2+A_{n}
\end{array}\right)$. Then $\hat{A}$ and $\tilde{A}$ are both Laplacian matrices and
\[
\log\left|A\right|=\ld\left(\tilde{A}\right)-\ld\left(\hat{A}\right)
\]
\end{lemma}
\begin{proof}
The matrices $\hat{A}$ and $\tilde{A}$ are Laplacian by constructions,
and we show that the eigenvalues of $\tilde{A}$ are exactly the concatenation
of the eigenvalues of $\hat{A}$ and $A$. Call $\lambda_{i}$ an
eigenvalue of $A$ with $x$ an associated eigenvector. Then the vector
$\left(\begin{array}{c}
x\\
-x
\end{array}\right)$ is an eigenvector of $\tilde{A}$ with associated eigenvalue $\lambda$.
Similarly, call $\mu_{i}$ an eigenvalue of $\hat{A}$ with $y$ an
associated eigenvector. Then $\mu$ is an eigenvalue of $\tilde{A}$
with associated eigenvector $\left(\begin{array}{c}
y\\
y
\end{array}\right)$. Since $\tilde{A}$ is exactly of size $2n$, the set of eigenvalues
of $\tilde{A}$ is exactly the concatenation of the eigenvalues of
$\hat{A}$ and $A$. By definition of the PLD: $\ld\left(\tilde{A}\right)=\sum_{i:\lambda_{i}>0}\log\lambda_{i}+\sum_{\mu_{i}>0}\log\mu_{i}$.
Since $A$ is invertible, $\lambda_{i}>0$ for all $i$ and $\sum_{i:\lambda_{i}>0}\log\lambda_{i}=\sum_{i}\log\lambda_{i}=\log\left|A\right|$.
Finally, by definition of the PLD, we get $\sum_{\mu_{i}>0}\log\mu_{i}=\ld\left(\hat{A}\right)$. 
\end{proof}

To any Laplacian $L$ we can associate a unique positive definite
matrix $F_{L}$ (up to a permutation), and this transform preserves
eigenvalues and matrix inequalities. We call this process ``floating''
of the Laplacian, by analogy to the ``grounding'' in the electrical
sense of the SDD matrix as a Laplacian introduced by Gremban (see
\cite{Gremban1996}, Chapter 4). 
\begin{definition}
\emph{Floating a Laplacian}. Consider $L$ a Laplacian matrix. Call
$F_{L}$ the matrix formed by removing the last row and the last column
from $L$. 
\end{definition}

The following lemma shows that the Laplacian matrix overdetermines
a system, and that no information is lost by floating it. 
\begin{lemma}
\label{lem:floating-properties}Consider $Z$ a (weighted) Laplacian
matrix of a connected graph, then: 
\begin{enumerate}
\item The eigenvalues of $F_{Z}$ are the positive eigenvalues of $Z$,
and the corresponding eigenvectors for $F_{Z}$ are the same eigenvectors,
truncated by the last coefficient. 
\item $\ld\left(Z\right)=\log\left|F_{Z}\right|$ 
\item Given $Z_{1},Z_{2}$ Laplacian matrices, we have $Z_{1}\preceq Z_{2}\Rightarrow F_{Z_{1}}\preceq F_{Z_{2}}$
. 
\end{enumerate}
\end{lemma}

The proof of this lemma is straightforward, and is contained in Appendix
B.

A Laplacian matrix can be considered either for its graphical properties,
or for its algebraic properties. Recent results have shown a deep
connection between these two aspects, and they let us develop a general
framework for computing determinants: consider a Laplacian $L_{G}$
identified to its graph $G$. Using graphical properties of $L_{G}$,
we can construct a subgraph $H$ of $G$ for which the PLD is easier
to compute and that is a good approximation of $G$ in the spectral
sense. Then we can float the subgraph $H$ and apply results of section
\ref{sec:Preconditioned-log-determinants} to approximate the remainder
with high probability. More precisely: 
\begin{eqnarray*}
\ld\left(L_{G}\right) & = & \log\left|F_{L_{G}}\right|\\
 & = & \ld\left(L_{H}\right)-\log\left|F_{L_{H}}\right|+\log\left|F_{L_{G}}\right|\\
 & = & \ld\left(L_{H}\right)+\log\left|F_{L_{H}}^{-1}F_{L_{G}}\right|
\end{eqnarray*}


The first term $\ld\left(L_{H}\right)$ is usually easier to compute
by considering the graphical properties of $L_{H}$, while the remainder
$\log\left|F_{L_{H}}^{-1}F_{L_{G}}\right|$ is approximated by sampling.
Preconditioner graphs $L_{H}$ are typically efficient to factorize
using Cholesky factorization, and close enough to $G$ so that the
sampling procedure from the previous section can be applied to compute
$\log\left|F_{L_{H}}^{-1}F_{L_{G}}\right|$. We will see how to adapt
Spielman and Teng's remarkable work on \emph{ultra-sparsifiers} to
produce good preconditioners $H$ for the determinant. 
