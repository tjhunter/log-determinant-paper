@article{Anandkumar,
author = {Anandkumar, Animashree and Tan, Vincent Y F and Willsky, Alan S},
file = {:home/tjhunter/Documents/Mendeley Desktop/Anandkumar, Tan, Willsky\_Unknown\_High-Dimensional Gaussian Graphical Model Selection Walk Summability and Local Separation Criterion.pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {gaussian graphical model selection,high-dimensional learning,local-separation,necessary conditions for model,property,selection,walk-summability},
title = {{High-Dimensional Gaussian Graphical Model Selection: Walk Summability and Local Separation Criterion}}
}
@article{Bekas,
author = {Bekas, C and Curioni, A},
file = {:home/tjhunter/Documents/Mendeley Desktop/Bekas, Curioni\_Unknown\_On projection methods for estimating the diagonal of a matrix inverse.pdf:pdf},
journal = {bugs.unica.it},
number = {2},
pages = {2011},
title = {{On projection methods for estimating the diagonal of a matrix inverse}},
url = {http://bugs.unica.it/SC2011/slides/files/general/gallopoulos.pdf},
volume = {58}
}
@article{Guionnet2000,
annote = {for wigner matrices},
author = {Guionnet, A and Matrices, Random},
file = {:home/tjhunter/Documents/Mendeley Desktop/Guionnet, Matrices\_2000\_in PROBABILITY CONCENTRATION OF THE SPECTRAL MEASURE FOR LARGE MATRICES.pdf:pdf},
pages = {119--136},
title = {{in PROBABILITY CONCENTRATION OF THE SPECTRAL MEASURE FOR LARGE MATRICES}},
volume = {5},
year = {2000}
}
@article{Hara2012a,
author = {Hara, Satoshi and Washio, Takashi},
file = {:home/tjhunter/Documents/Mendeley Desktop/Hara, Washio\_2012\_Group Sparse Inverse Covariance Selection.pdf:pdf},
keywords = {alternating direction method of,dual augmented la-,grangian,multipliers,sparse inverse covariance selection},
number = {1},
pages = {108--115},
title = {{Group Sparse Inverse Covariance Selection}},
volume = {1},
year = {2012}
}
@article{Kollaa,
author = {Kolla, Alexandra},
file = {:home/tjhunter/Documents/Mendeley Desktop/Kolla\_Unknown\_Subgraph Sparsification and Nearly Optimal Ultrasparsifiers Categories and Subject Descriptors.pdf:pdf},
isbn = {9781450300506},
keywords = {ap-,graph laplacian,graph sparsification,proximation algorithm,ultrasparsifiers},
title = {{Subgraph Sparsification and Nearly Optimal Ultrasparsifiers Categories and Subject Descriptors}}
}
@article{Lasowski2011,
author = {Lasowski, Ruxandra and Tevs, Art and Wand, Michael and Seidel, Hans-Peter},
doi = {10.1109/CVPR.2011.5995489},
file = {:home/tjhunter/Documents/Mendeley Desktop/Lasowski et al.\_2011\_Wavelet belief propagation for large scale inference problems.pdf:pdf},
isbn = {978-1-4577-0394-2},
journal = {Cvpr 2011},
month = jun,
pages = {1921--1928},
publisher = {Ieee},
title = {{Wavelet belief propagation for large scale inference problems}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5995489},
year = {2011}
}
@article{Li2007,
author = {Li, X Sherry},
file = {:home/tjhunter/Documents/Mendeley Desktop/Li\_2007\_Techniques for Sparse.pdf:pdf},
title = {{Techniques for Sparse}},
year = {2007}
}
@article{Magen,
archivePrefix = {arXiv},
arxivId = {arXiv:1005.2724v3},
author = {Magen, Avner and Zouzias, Anastasios},
eprint = {arXiv:1005.2724v3},
file = {:home/tjhunter/Documents/Mendeley Desktop/Magen, Zouzias\_Unknown\_Low Rank Matrix-valued Chernoff Bounds and Approximate Matrix Multiplication.pdf:pdf},
keywords = {Chernoff Bounds, matrix-valued,Khinthine Inequalit},
title = {{Low Rank Matrix-valued Chernoff Bounds and Approximate Matrix Multiplication}}
}
@article{Maleki,
archivePrefix = {arXiv},
arxivId = {arXiv:1211.2532v2},
author = {Maleki, Arian and Wong, Ian},
eprint = {arXiv:1211.2532v2},
file = {:home/tjhunter/Documents/Mendeley Desktop/Maleki, Wong\_Unknown\_Iterative Thresholding Algorithm for Sparse Inverse Covariance Estimation.pdf:pdf},
number = {i},
pages = {1--27},
title = {{Iterative Thresholding Algorithm for Sparse Inverse Covariance Estimation}}
}
@article{Raghavendra,
author = {Raghavendra, Prasad and Steurer, David and Tech, Georgia},
file = {:home/tjhunter/Documents/Mendeley Desktop/Raghavendra, Steurer, Tech\_Unknown\_Approximations for the Isoperimetric and Spectral Profile of Graphs and Related Parameters.pdf:pdf},
isbn = {9781450300506},
keywords = {approximation algorithm,graph expansion,ming,semidefinite program-,small-set expansion,sparse principal component analysis,spectral profile},
title = {{Approximations for the Isoperimetric and Spectral Profile of Graphs and Related Parameters}}
}
@article{Rogers,
archivePrefix = {arXiv},
arxivId = {arXiv:0803.1553v2},
author = {Rogers, Tim and Isaac, P},
eprint = {arXiv:0803.1553v2},
file = {:home/tjhunter/Documents/Mendeley Desktop/Rogers, Isaac\_Unknown\_Cavity Approach to the Spectral Density of Sparse Symmetric Random Matrices.pdf:pdf},
number = {3},
pages = {1--7},
title = {{Cavity Approach to the Spectral Density of Sparse Symmetric Random Matrices}}
}
@article{Shawe-taylor,
author = {Shawe-taylor, John and Williams, Christopher K I and Edward, King and London, Street},
file = {:home/tjhunter/Documents/Mendeley Desktop/Shawe-taylor et al.\_Unknown\_On the Eigenspectrum of the Gram Matrix and the Generalisation Error of Kernel PCA.pdf:pdf},
pages = {1--12},
title = {{On the Eigenspectrum of the Gram Matrix and the Generalisation Error of Kernel PCA}}
}
@article{Silva,
archivePrefix = {arXiv},
arxivId = {arXiv:1107.0088v2},
author = {Silva, Marcel K De Carli and Harvey, Nicholas J A},
eprint = {arXiv:1107.0088v2},
file = {:home/tjhunter/Documents/Mendeley Desktop/Silva, Harvey\_Unknown\_Sparse Sums of Positive Semidefinite Matrices.pdf:pdf},
title = {{Sparse Sums of Positive Semidefinite Matrices}}
}
@article{Spielman,
author = {Spielman, Daniel},
file = {:home/tjhunter/Documents/Mendeley Desktop/Spielman\_Unknown\_Spectral Graph Theory.pdf:pdf},
title = {{Spectral Graph Theory}}
}
@article{Spielman2010a,
archivePrefix = {arXiv},
arxivId = {arXiv:0808.4134v3},
author = {Spielman, Daniel A},
eprint = {arXiv:0808.4134v3},
file = {:home/tjhunter/Documents/Mendeley Desktop/Spielman\_2008\_Spectral sparsification of graphs.pdf:pdf},
journal = {Arxiv preprint arXiv:0808.4134},
title = {{Spectral sparsification of graphs}},
url = {http://arxiv.org/abs/0808.4134},
year = {2008}
}
@article{Verhoosel2006,
author = {Verhoosel, C. V. and Guti\'{e}rrez, M. a. and Hulshoff, S. J.},
doi = {10.1002/nme.1712},
file = {:home/tjhunter/Documents/Mendeley Desktop/Verhoosel, Guti\'{e}rrez, Hulshoff\_2006\_Iterative solution of the random eigenvalue problem with application to spectral stochastic finite.pdf:pdf},
issn = {0029-5981},
journal = {International Journal for Numerical Methods in Engineering},
keywords = {inverse power method,random eigenvalue problem,stochastic finite elements},
month = oct,
number = {4},
pages = {401--424},
title = {{Iterative solution of the random eigenvalue problem with application to spectral stochastic finite element systems}},
url = {http://doi.wiley.com/10.1002/nme.1712},
volume = {68},
year = {2006}
}
@article{Xiao2009,
author = {Xiao, Lin},
file = {:home/tjhunter/Documents/Mendeley Desktop/Xiao\_2009\_A Proximal-Gradient Homotopy Method for the Least-Squares Problem.pdf:pdf},
title = {{A Proximal-Gradient Homotopy Method for the Least-Squares Problem}},
year = {2009}
}
@article{Yuan2010,
author = {Yuan, Ming},
file = {:home/tjhunter/Documents/Mendeley Desktop/Yuan\_2010\_High dimensional inverse covariance matrix estimation via linear programming.pdf:pdf},
journal = {The Journal of Machine Learning Research},
keywords = {covariance selection,dantzig selector,gaussian graphical model,inverse covariance,lasso,linear programming,matrix,oracle inequality,sparsity},
pages = {2261--2286},
title = {{High dimensional inverse covariance matrix estimation via linear programming}},
url = {http://dl.acm.org/citation.cfm?id=1859930},
volume = {11},
year = {2010}
}
@article{Kolar2012,
author = {Kolar, Mladen and Xing, Eric P},
file = {:home/tjhunter/Documents/Mendeley Desktop/Kolar, Xing\_2012\_Estimating Sparse Precision Matrices from Data with Missing Values.pdf:pdf},
title = {{Estimating Sparse Precision Matrices from Data with Missing Values}},
year = {2012}
}
@article{Koutis2010,
archivePrefix = {arXiv},
arxivId = {arXiv:1003.2958v3},
author = {Koutis, Ioannis and Miller, Gary L and Peng, Richard},
eprint = {arXiv:1003.2958v3},
file = {:home/tjhunter/Documents/Mendeley Desktop/Koutis, Miller, Peng\_2010\_Approaching optimality for solving SDD linear systems.pdf:pdf},
pages = {1--16},
title = {{Approaching optimality for solving SDD linear systems}},
year = {2010}
}
@article{Of2000,
author = {Of, Ampling and With, Ields},
file = {:home/tjhunter/Documents/Mendeley Desktop/Of, With\_2000\_NORWEGIAN UNIVERSITY OF SCIENCE AND TECHNOLOGY Fast Sampling of Gaussian Markov Random Fields with Applications.pdf:pdf},
title = {{NORWEGIAN UNIVERSITY OF SCIENCE AND TECHNOLOGY Fast Sampling of Gaussian Markov Random Fields with Applications}},
year = {2000}
}
@article{Olsen2012,
author = {Olsen, Peder A and Nocedal, Jorge and Rennie, Stephen J},
file = {:home/tjhunter/Documents/Mendeley Desktop/Olsen, Nocedal, Rennie\_2012\_Newton-Like Methods for Sparse Inverse Covariance Estimation.pdf:pdf},
title = {{Newton-Like Methods for Sparse Inverse Covariance Estimation}},
year = {2012}
}
@article{Orecchia,
archivePrefix = {arXiv},
arxivId = {arXiv:1010.4108v1},
author = {Orecchia, Lorenzo},
eprint = {arXiv:1010.4108v1},
file = {:home/tjhunter/Documents/Mendeley Desktop/Orecchia\_Unknown\_Towards an SDP-based Approach to Spectral Methods A Nearly-Linear-Time Algorithm for Graph Partitioning and Decompositi.pdf:pdf},
title = {{Towards an SDP-based Approach to Spectral Methods A Nearly-Linear-Time Algorithm for Graph Partitioning and Decomposition}}
}
@article{Yuan2011,
author = {Yuan, GX},
file = {:home/tjhunter/Documents/Mendeley Desktop/Yuan\_2011\_An improved GLMNET for l1-regularized logistic regression.pdf:pdf},
journal = {Proceedings of the 17th ACM SIGKDD \ldots},
number = {1},
pages = {1--34},
title = {{An improved GLMNET for l1-regularized logistic regression}},
url = {http://users.cis.fiu.edu/~lzhen001/activities/KDD2011Program/docs/p33.pdf},
year = {2011}
}
@article{Duff2009,
author = {Duff, Iain S},
file = {:home/tjhunter/Documents/Mendeley Desktop/Duff\_2009\_Direct methods for sparse matrices Introduction Lecture 2 Multifrontal methods.pdf:pdf},
title = {{Direct methods for sparse matrices Introduction Lecture 2 Multifrontal methods}},
year = {2009}
}
@article{Chung2012,
author = {Chung, Fan and Zhao, Wenbo},
file = {:home/tjhunter/Documents/Mendeley Desktop/Chung, Zhao\_2012\_Ranking and Sparsifying a Connection Graph.pdf:pdf},
pages = {66--77},
title = {{Ranking and Sparsifying a Connection Graph}},
year = {2012}
}
@article{Ellens2011,
author = {Ellens, W. and Spieksma, F.M. and {Van Mieghem}, P. and Jamakovic, a. and Kooij, R.E.},
doi = {10.1016/j.laa.2011.02.024},
file = {:home/tjhunter/Documents/Mendeley Desktop/Ellens et al.\_2011\_Effective graph resistance.\_2011\_Effective graph resistance:\_2011\_Effective graph resistance},
issn = {00243795},
journal = {Linear Algebra and its Applications},
keywords = {effective resistance},
month = nov,
number = {10},
pages = {2491--2506},
title = {{Effective graph resistance}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0024379511001443},
volume = {435},
year = {2011}
}
@article{Johnson2001,
author = {Johnson, JK},
file = {:home/tjhunter/Documents/Mendeley Desktop/Johnson\_2001\_Walk-summable Gauss-Markov random fields.pdf:pdf},
journal = {Unpublished manuscript, available at http://www. mit. \ldots},
keywords = {walksum},
mendeley-tags = {walksum},
pages = {1--23},
title = {{Walk-summable Gauss-Markov random fields}},
url = {http://ssg.mit.edu/group/jasonj/johnson-walksum-tr02.pdf},
volume = {2002},
year = {2001}
}
@article{Batson2009,
archivePrefix = {arXiv},
arxivId = {arXiv:0808.0163v3},
author = {Batson, Joshua and Spielman, Daniel A},
eprint = {arXiv:0808.0163v3},
file = {:home/tjhunter/Documents/Mendeley Desktop/Batson, Spielman\_2009\_Twice-Ramanujan Sparsifiers.pdf:pdf},
pages = {1--21},
title = {{Twice-Ramanujan Sparsifiers}},
year = {2009}
}
@article{Bekas2009,
address = {New York, New York, USA},
author = {Bekas, C. and Curioni, A. and Fedulova, I.},
doi = {10.1145/1645413.1645421},
file = {:home/tjhunter/Documents/Mendeley Desktop/Bekas, Curioni, Fedulova\_2009\_Low cost high performance uncertainty quantification.pdf:pdf},
isbn = {9781605587165},
journal = {Proceedings of the 2nd Workshop on High Performance Computational Finance - WHPCF '09},
keywords = {inverse covariance matrices,itera-,iterative solvers,massive,quadratic cost,stochastic estimation,tive refinement},
pages = {1--8},
publisher = {ACM Press},
title = {{Low cost high performance uncertainty quantification}},
url = {http://portal.acm.org/citation.cfm?doid=1645413.1645421},
year = {2009}
}
@article{Blocki2012,
archivePrefix = {arXiv},
arxivId = {arXiv:1204.2136v1},
author = {Blocki, Jeremiah and Blum, Avrim and Datta, Anupam and Sheffet, Or},
eprint = {arXiv:1204.2136v1},
file = {:home/tjhunter/Documents/Mendeley Desktop/Blocki et al.\_2012\_The Johnson-Lindenstrauss Transform Itself Preserves Differential Privacy.pdf:pdf},
title = {{The Johnson-Lindenstrauss Transform Itself Preserves Differential Privacy}},
year = {2012}
}
@article{Chow2000,
author = {Chow, Edmond},
file = {:home/tjhunter/Documents/Mendeley Desktop/Chow\_2000\_A priori sparsity patterns for parallel sparse approximate inverse preconditioners.pdf:pdf},
title = {{A priori sparsity patterns for parallel sparse approximate inverse preconditioners}},
url = {https://computation.llnl.gov/casc/linear\_solvers/pubs/SLS\_struct.pdf},
year = {2000}
}
@article{Haemers1995,
author = {Haemers, Willem H.},
doi = {10.1016/0024-3795(95)00199-2},
file = {:home/tjhunter/Documents/Mendeley Desktop/Haemers\_1995\_Interlacing eigenvalues and graphs.pdf:pdf},
issn = {00243795},
journal = {Linear Algebra and its Applications},
month = sep,
pages = {593--616},
title = {{Interlacing eigenvalues and graphs}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0024379595001992},
volume = {226-228},
year = {1995}
}
@article{Johnson2009,
address = {New York, New York, USA},
author = {Johnson, Jason K. and Chernyak, Vladimir Y. and Chertkov, Michael},
doi = {10.1145/1553374.1553436},
file = {:home/tjhunter/Documents/Mendeley Desktop/Johnson, Chernyak, Chertkov\_2009\_Orbit-product representation and correction of Gaussian belief propagation.pdf:pdf},
isbn = {9781605585161},
journal = {Proceedings of the 26th Annual International Conference on Machine Learning - ICML '09},
pages = {1--8},
publisher = {ACM Press},
title = {{Orbit-product representation and correction of Gaussian belief propagation}},
url = {http://portal.acm.org/citation.cfm?doid=1553374.1553436},
year = {2009}
}
@article{Lee2012,
archivePrefix = {arXiv},
arxivId = {arXiv:1206.1623v4},
author = {Lee, Jason D and Saunders, Michael A},
eprint = {arXiv:1206.1623v4},
file = {:home/tjhunter/Documents/Mendeley Desktop/Lee, Saunders\_2012\_Proximal Newton-type methods for convex optimization.pdf:pdf},
pages = {1--25},
title = {{Proximal Newton-type methods for convex optimization}},
year = {2012}
}
@article{Wang2010a,
author = {Wang, Chengjing},
file = {:home/tjhunter/Documents/Mendeley Desktop/Wang\_2010\_Solving log-determinant optimization problems by a Newton-CG primal proximal point algorithm.pdf:pdf},
journal = {SIAM Journal on Optimization},
keywords = {log-determinant optimization problem,newton,proximal-point algorithm,s method,sparse inverse covariance selec-,tion},
pages = {1--24},
title = {{Solving log-determinant optimization problems by a Newton-CG primal proximal point algorithm}},
url = {http://www.math.nus.edu.sg/~matsundf/logdet-NAL-29Sep09.pdf},
volume = {117543},
year = {2010}
}
@article{Weiss2001,
abstract = {Graphical models, such as Bayesian networks and Markov random fields, represent statistical dependencies of variables by a graph. Local "belief propagation" rules of the sort proposed by Pearl (1988) are guaranteed to converge to the correct posterior probabilities in singly connected graphs. Recently, good performance has been obtained by using these same rules on graphs with loops, a method we refer to as loopy belief propagation. Perhaps the most dramatic instance is the near Shannon-limit performance of "Turbo codes," whose decoding algorithm is equivalent to loopy propagation. Except for the case of graphs with a single loop, there has been little theoretical understanding of loopy propagation. Here we analyze belief propagation in networks with arbitrary topologies when the nodes in the graph describe jointly gaussian random variables. We give an analytical formula relating the true posterior probabilities with those calculated using loopy propagation. We give sufficient conditions for convergence and show that when belief propagation converges, it gives the correct posterior means for all graph topologies, not just networks with a single loop. These results motivate using the powerful belief propagation algorithm in a broader class of networks and help clarify the empirical performance results.},
author = {Weiss, Y and Freeman, W T},
doi = {10.1162/089976601750541769},
file = {:home/tjhunter/Documents/Mendeley Desktop/Weiss, Freeman\_2001\_Correctness of belief propagation in Gaussian graphical models of arbitrary topology.pdf:pdf},
issn = {0899-7667},
journal = {Neural computation},
month = oct,
number = {10},
pages = {2173--200},
pmid = {11570995},
title = {{Correctness of belief propagation in Gaussian graphical models of arbitrary topology.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11570995},
volume = {13},
year = {2001}
}
@article{,
file = {:home/tjhunter/Documents/Mendeley Desktop/Unknown\_Unknown\_Symmetric Diagonally-Dominant Matrices and.pdf:pdf},
pages = {1--7},
title = {{Symmetric Diagonally-Dominant Matrices and}}
}
@article{Boman2004,
author = {Boman, Erik G. and Chen, Doron and Hendrickson, Bruce and Toledo, Sivan},
doi = {10.1002/nla.343},
file = {:home/tjhunter/Documents/Mendeley Desktop/Boman et al.\_2004\_Maximum-weight-basis preconditioners.pdf:pdf},
issn = {1070-5325},
journal = {Numerical Linear Algebra with Applications},
keywords = {matroids,maximum-,preconditioning,sparse linear solvers,support preconditioners,support theory,weight bases},
month = oct,
number = {89},
pages = {695--721},
title = {{Maximum-weight-basis preconditioners}},
url = {http://doi.wiley.com/10.1002/nla.343},
volume = {11},
year = {2004}
}
@article{Dellaert2010,
author = {Dellaert, Frank and Carlson, Justin and Ila, Viorela},
file = {:home/tjhunter/Documents/Mendeley Desktop/Dellaert, Carlson, Ila\_2010\_Subgraph-preconditioned conjugate gradients for large scale SLAM.pdf:pdf},
journal = {Intelligent Robots and \ldots},
pages = {1--6},
title = {{Subgraph-preconditioned conjugate gradients for large scale SLAM}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5650422},
year = {2010}
}
@book{Doyle2006,
author = {Doyle, Peter G and Snell, J Laurie},
edition = {13},
file = {:home/tjhunter/Documents/Mendeley Desktop/Doyle, Snell\_2006\_Random walks and electric networks.pdf:pdf},
isbn = {978-0883850244},
keywords = {effective resistance,electrical network,escape probability},
number = {July},
pages = {150},
publisher = {Mathematical Association of America},
title = {{Random walks and electric networks}},
url = {http://arxiv.org/abs/math/0001057v1},
year = {2006}
}
@article{Eigenvalue2009,
author = {Eigenvalue, T H E and Of, Distribution and Complements, Schur and Nonstrictly, O F and Dominant, Diagonally},
file = {:home/tjhunter/Documents/Mendeley Desktop/Eigenvalue et al.\_2009\_The eigenvalue distribution of schur complements of nonstrictly diagonally dominant matrices and general h−ma.pdf:pdf},
keywords = {1,15a15,15a18,ams subject classifications,diagonally dominant,eigenvalue distribution,general h,generalized,im-,introduction,matrices,schur complements,special matrices has various,the eigenvalue distribution of},
number = {December},
pages = {801--820},
title = {{The eigenvalue distribution of schur complements of nonstrictly diagonally dominant matrices and general h−matrices ∗}},
volume = {18},
year = {2009}
}
@article{Ghaoui2006,
author = {{El Ghaoui}, Laurent and Aspremont, Alexandre and Natsoulis, Georges},
file = {:home/tjhunter/Documents/Mendeley Desktop/El Ghaoui, Aspremont, Natsoulis\_2006\_Convex Optimization Techniques for Fitting Sparse Gaussian Graphical Models.pdf:pdf},
title = {{Convex Optimization Techniques for Fitting Sparse Gaussian Graphical Models}},
year = {2006}
}
@article{Friedman2008,
abstract = {We consider the problem of estimating sparse graphs by a lasso penalty applied to the inverse covariance matrix. Using a coordinate descent procedure for the lasso, we develop a simple algorithm--the graphical lasso--that is remarkably fast: It solves a 1000-node problem ( approximately 500,000 parameters) in at most a minute and is 30-4000 times faster than competing methods. It also provides a conceptual link between the exact problem and the approximation suggested by Meinshausen and B\"{u}hlmann (2006). We illustrate the method on some cell-signaling data from proteomics.},
author = {Friedman, Jerome and Hastie, Trevor and Tibshirani, Robert},
doi = {10.1093/biostatistics/kxm045},
file = {:home/tjhunter/Documents/Mendeley Desktop/Friedman, Hastie, Tibshirani\_2008\_Sparse inverse covariance estimation with the graphical lasso.pdf:pdf},
issn = {1468-4357},
journal = {Biostatistics (Oxford, England)},
keywords = {Algorithms,Animals,Biometry,Biometry: methods,Data Interpretation, Statistical,Humans,Models, Statistical,Neural Networks (Computer),Proteomics,Proteomics: methods,Reference Values,Regression Analysis,Sample Size,Signal Transduction,Time Factors},
month = jul,
number = {3},
pages = {432--41},
pmid = {18079126},
title = {{Sparse inverse covariance estimation with the graphical lasso.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3019769\&tool=pmcentrez\&rendertype=abstract},
volume = {9},
year = {2008}
}
@article{Gu2007,
author = {Gu, Lie and Xing, Eric P. and Kanade, Takeo},
doi = {10.1109/CVPR.2007.382982},
file = {:home/tjhunter/Documents/Mendeley Desktop/Gu, Xing, Kanade\_2007\_Learning GMRF Structures for Spatial Priors.pdf:pdf},
isbn = {1-4244-1179-3},
journal = {2007 IEEE Conference on Computer Vision and Pattern Recognition},
month = jun,
pages = {1--6},
publisher = {Ieee},
title = {{Learning GMRF Structures for Spatial Priors}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4270007},
year = {2007}
}
@article{Jones2004,
author = {Jones, Beatrix and Carvalho, Carlos and Dobra, Adrian and Hans, Chris and Carter, Chris and West, Mike},
file = {:home/tjhunter/Documents/Mendeley Desktop/Jones et al.\_2004\_Archival Version including Appendicies Experiments in Stochastic Computation for High-Dimensional Graphical Models.pdf:pdf},
pages = {1--44},
title = {{Archival Version including Appendicies : Experiments in Stochastic Computation for High-Dimensional Graphical Models}},
year = {2004}
}
@article{Kolla,
archivePrefix = {arXiv},
arxivId = {arXiv:0912.1623v1},
author = {Kolla, Alexandra},
eprint = {arXiv:0912.1623v1},
file = {:home/tjhunter/Documents/Mendeley Desktop/Kolla\_Unknown\_Subgraph Sparsification and Nearly Optimal Ultrasparsifiers.pdf:pdf},
title = {{Subgraph Sparsification and Nearly Optimal Ultrasparsifiers}}
}
@article{Rademacher,
archivePrefix = {arXiv},
arxivId = {arXiv:0807.1496v1},
author = {Rademacher, Luis},
eprint = {arXiv:0807.1496v1},
file = {:home/tjhunter/Documents/Mendeley Desktop/Rademacher\_Unknown\_Expanders via Random Spanning Trees.pdf:pdf},
pages = {1--14},
title = {{Expanders via Random Spanning Trees}}
}
@article{Schafer2005,
author = {Sch\"{a}fer, J and Strimmer, K},
file = {:home/tjhunter/Documents/Mendeley Desktop/Sch\"{a}fer, Strimmer\_2005\_A shrinkage approach to large-scale covariance matrix estimation and implications for functional genomics.pdf:pdf},
journal = {Statistical applications in genetics and \ldots},
title = {{A shrinkage approach to large-scale covariance matrix estimation and implications for functional genomics}},
url = {http://uni-leipzig.de/~strimmer/lab/publications/journals/shrinkcov2005.pdf},
year = {2005}
}
@article{Smith1992,
author = {Smith, Ronald L.},
doi = {10.1016/0024-3795(92)90321-Z},
file = {:home/tjhunter/Documents/Mendeley Desktop/Smith\_1992\_Some interlacing properties of the Schur complement of a Hermitian matrix.pdf:pdf},
issn = {00243795},
journal = {Linear Algebra and its Applications},
month = dec,
pages = {137--144},
title = {{Some interlacing properties of the Schur complement of a Hermitian matrix}},
url = {http://linkinghub.elsevier.com/retrieve/pii/002437959290321Z},
volume = {177},
year = {1992}
}
@article{Spielman2009b,
abstract = {Boman and Hendrickson [BH01] observed that one can solve linear systems in Laplacian matrices in time O m3/2+o(1) ln(1/ǫ) by preconditioning with the Laplacian of a low-stretch spanning tree. By examining the distribution of eigenvalues of the preconditioned linear system, we prove that the preconditioned conjugate gradient will actually solve the linear system in time O m4/3 ln(1/ǫ) .},
archivePrefix = {arXiv},
arxivId = {arXiv:0903.2816v1},
author = {Spielman, Daniel A and Woo, Jaeoh},
eprint = {arXiv:0903.2816v1},
file = {:home/tjhunter/Documents/Mendeley Desktop/Spielman, Woo\_2009\_A Note on Preconditioning by Low-Stretch Spanning Trees.pdf:pdf},
pages = {1--4},
title = {{A Note on Preconditioning by Low-Stretch Spanning Trees}},
year = {2009}
}
@article{Ahn,
author = {Ahn, Kook Jin and Mcgregor, Andrew},
file = {:home/tjhunter/Documents/Mendeley Desktop/Ahn, Mcgregor\_Unknown\_Analyzing Graph Structure via Linear Measurements.pdf:pdf},
pages = {459--467},
title = {{Analyzing Graph Structure via Linear Measurements}}
}
@article{Alexandrov1996,
author = {Alexandrov, V N and Lakka, S},
file = {:home/tjhunter/Documents/Mendeley Desktop/Alexandrov, Lakka\_1996\_Comparison of Three Monte Carlo Methods for Matrix Inversion.pdf:pdf},
journal = {Euro-Par'96 Parallel Processing},
title = {{Comparison of Three Monte Carlo Methods for Matrix Inversion}},
url = {http://www.springerlink.com/index/571j624n71101311.pdf},
year = {1996}
}
@article{Avron2011,
archivePrefix = {arXiv},
arxivId = {arXiv:1110.4437v1},
author = {Avron, Haim},
eprint = {arXiv:1110.4437v1},
file = {:home/tjhunter/Documents/Mendeley Desktop/Avron\_2011\_Effective Stiffness Generalizing Effective Resistance Sampling to Finite Element Matrices.pdf:pdf},
pages = {1--18},
title = {{Effective Stiffness : Generalizing Effective Resistance Sampling to Finite Element Matrices}},
year = {2011}
}
@article{Eastwood2012,
author = {Eastwood, Shawn and Wan, Justin W L},
doi = {10.1002/nla},
file = {:home/tjhunter/Documents/Mendeley Desktop/Eastwood, Wan\_2012\_Finding off-diagonal entries of the inverse of a large symmetric sparse matrix.pdf:pdf},
journal = {Numerical Linear Algebra with \ldots},
keywords = {computational,computational complexity,matrix inversion,mesh,nested dissection,off-diagonal entries,sparse matrix},
title = {{Finding off-diagonal entries of the inverse of a large symmetric sparse matrix}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/nla.1826/full},
year = {2012}
}
@article{Gittens2011,
abstract = {This work introduces the minimax Laplace transform method, a modification of the cumulant-based matrix Laplace transform method developed in [Tro11c] that yields both upper and lower bounds on each eigenvalue of a sum of random self-adjoint matrices. This machinery is used to derive eigenvalue analogs of the classical Chernoff, Bennett, and Bernstein bounds. Two examples demonstrate the efficacy of the minimax Laplace transform. The first concerns the effects of column sparsification on the spectrum of a matrix with orthonormal rows. Here, the behavior of the singular values can be described in terms of coherence-like quantities. The second example addresses the question of relative accuracy in the estimation of eigenvalues of the covariance matrix of a random process. Standard results on the convergence of sample covariance matrices provide bounds on the number of samples needed to obtain relative accuracy in the spectral norm, but these results only guarantee relative accuracy in the estimate of the maximum eigenvalue. The minimax Laplace transform argument establishes that if the lowest eigenvalues decay sufficiently fast, $\Omega$($\epsilon$−2 $\kappa$2 log p) samples, where $\kappa$ = $\lambda$1(C)/$\lambda$ (C), are sufficient to ensure that the dominant eigenvalues of the covariance matrix of a N (0, C) random vector are estimated to within a factor of 1 ± $\epsilon$ with high probability.},
author = {Gittens, Alex and Tropp, Joel A},
file = {:home/tjhunter/Documents/Mendeley Desktop/Gittens, Tropp\_2011\_Tail bounds for all eigenvalues of a sum of random matrices.pdf:pdf},
number = {C},
pages = {1--23},
title = {{Tail bounds for all eigenvalues of a sum of random matrices}},
volume = {1},
year = {2011}
}
@article{Jones,
author = {Jones, Beatrix and West, Mike},
file = {:home/tjhunter/Documents/Mendeley Desktop/Jones, West\_Unknown\_Covariance decomposition in undirected Gaussian graphical models.pdf:pdf},
pages = {1--12},
title = {{Covariance decomposition in undirected Gaussian graphical models}}
}
@article{Koutis,
author = {Koutis, Ioannis and Levin, Alex and Peng, Richard},
file = {:home/tjhunter/Documents/Mendeley Desktop/Koutis, Levin, Peng\_Unknown\_Improved Spectral Sparsification and Numerical Algorithms for SDD Matrices.pdf:pdf},
journal = {Symposium on Theoretical \ldots},
keywords = {4230,and phrases spectral sparsification,digital object identifier 10,linear system solving,lipics,p,xxx,yyy},
pages = {1--12},
title = {{Improved Spectral Sparsification and Numerical Algorithms for SDD Matrices}},
url = {http://hal.archives-ouvertes.fr/hal-00678205/},
volume = {i},
year = {2012}
}
@article{Luxburg2011,
archivePrefix = {arXiv},
arxivId = {arXiv:1003.1266v2},
author = {Luxburg, Ulrike Von and Radl, Agnes and Hein, Matthias},
eprint = {arXiv:1003.1266v2},
file = {:home/tjhunter/Documents/Mendeley Desktop/Luxburg, Radl, Hein\_2011\_Hitting and commute times in large graphs are often misleading.pdf:pdf},
title = {{Hitting and commute times in large graphs are often misleading}},
year = {2011}
}
@article{Sarkar,
author = {Sarkar, Purnamrita and Moore, Andrew W},
file = {:home/tjhunter/Documents/Mendeley Desktop/Sarkar, Moore\_Unknown\_A Tractable Approach to Finding Closest Truncated-commute-time Neighbors in Large Graphs.pdf:pdf},
title = {{A Tractable Approach to Finding Closest Truncated-commute-time Neighbors in Large Graphs}}
}
@article{Spielman2009,
abstract = {We present a nearly linear time algorithm that produces high-quality spectral sparsifiers of weighted graphs. Given as input a weighted graph \$G=(V,E,w)\$ and a parameter \$\backslash epsilon>0\$, we produce a weighted subgraph \$H=(V,\backslash tilde\{E\},\backslash tilde\{w\})\$ of G such that \$|\backslash tilde\{E\}|=O(n\backslash log n/\backslash epsilon\^{}2)\$ and all \$x\backslash in\backslash mathbb\{R\}\^{}V\$ satisfy \$(1-\backslash epsilon)\backslash sum\_\{uv\backslash in E\}\backslash,(x(u)-x(v))\^{}2w\_\{uv\}\backslash leq\backslash sum\_\{uv\backslash in\backslash tilde\{E\}\}\backslash,(x(u)-x(v))\^{}2\backslash tilde\{w\}\_\{uv\}\backslash leq(1+\backslash epsilon)\backslash sum\_\{uv\backslash in E\}\backslash,(x(u)-x(v))\^{}2w\_\{uv\}\$. This improves upon the spectral sparsifiers constructed by Spielman and Teng, which had \$O(n\backslash log\^{}\{c\}n)\$ edges for some large constant c, and upon the cut sparsifiers of Bencz\'{u}r and Karger, which only satisfied these inequalities for \$x\backslash in\backslash\{0,1\backslash\}\^{}V\$. A key ingredient in our algorithm is a subroutine of independent interest: a nearly linear time algorithm that builds a data structure from which we can query the approximate effective resistance between any two vertices in a graph in \$O(\backslash log n)\$ time.},
archivePrefix = {arXiv},
arxivId = {arXiv:0803.0929v4},
author = {Spielman, Daniel A and Srivastava, Nikhil},
doi = {10.1137/080734029},
eprint = {arXiv:0803.0929v4},
file = {:home/tjhunter/Documents/Mendeley Desktop/Spielman, Srivastava\_2011\_Graph Sparsification by Effective Resistances.pdf:pdf},
journal = {SIAM Journal on Computing},
keywords = {electrical flows,sparsification,spectral graph theory},
number = {6},
pages = {1913--1926},
title = {{Graph Sparsification by Effective Resistances}},
url = {http://epubs.siam.org/doi/abs/10.1137/080734029},
volume = {40},
year = {2011}
}
@article{Vershynin,
archivePrefix = {arXiv},
arxivId = {arXiv:math/0503442v3},
author = {Vershynin, Mark Rudelsonroman},
eprint = {0503442v3},
file = {:home/tjhunter/Documents/Mendeley Desktop/Vershynin\_Unknown\_Sampling from large matrices an approach through geometric functional analysis.pdf:pdf},
pages = {1--20},
primaryClass = {arXiv:math},
title = {{Sampling from large matrices: an approach through geometric functional analysis}}
}
@article{Boutsidis2012,
archivePrefix = {arXiv},
arxivId = {arXiv:1204.0062v1},
author = {Boutsidis, Christos},
eprint = {arXiv:1204.0062v1},
file = {:home/tjhunter/Documents/Mendeley Desktop/Boutsidis\_2012\_Improved matrix algorithms via the Subsampled Randomized Hadamard Transform arXiv 1204 . 0062v1 cs . DS 31 Mar 2012.pdf:pdf},
title = {{Improved matrix algorithms via the Subsampled Randomized Hadamard Transform arXiv : 1204 . 0062v1 [ cs . DS ] 31 Mar 2012}},
year = {2012}
}
@article{Bradley2011,
author = {Bradley, JK and Kyrola, A},
file = {:home/tjhunter/Documents/Mendeley Desktop/Bradley, Kyrola\_2011\_Parallel coordinate descent for l1-regularized loss minimization.pdf:pdf},
journal = {Arxiv preprint arXiv: \ldots},
number = {1998},
title = {{Parallel coordinate descent for l1-regularized loss minimization}},
url = {http://arxiv.org/abs/1105.5379},
year = {2011}
}
@article{Foygel2010,
archivePrefix = {arXiv},
arxivId = {arXiv:1102.3923v2},
author = {Foygel, Rina and Srebro, Nathan},
eprint = {arXiv:1102.3923v2},
file = {:home/tjhunter/Documents/Mendeley Desktop/Foygel, Srebro\_2010\_Concentration-Based Guarantees for Low-Rank Matrix Reconstruction.pdf:pdf},
number = {1},
pages = {1--19},
title = {{Concentration-Based Guarantees for Low-Rank Matrix Reconstruction}},
year = {2010}
}
@article{Boyd2008,
author = {Ghosh, Arpita and Boyd, Stephen and Saberi, Amin},
doi = {10.1137/050645452},
file = {:home/tjhunter/Documents/Mendeley Desktop/Boyd\_2008\_Minimizing Effective Resistance.pdf:pdf},
isbn = {5710001848},
journal = {SIAM Review},
keywords = {050645452,05c12,05c50,1,10,1137,90c25,90c35,90c46,ams subject classifications,an undi-,and m edges,doi,e,electrical network,i,introduction,let n be a,network with n nodes,weighted graph,weighted laplacian eigenvalues},
number = {1},
pages = {37--66},
title = {{Minimizing Effective Resistance}},
volume = {50},
year = {2008}
}
@article{Hopcroft,
author = {Hopcroft, John and Sheldon, Daniel},
file = {:home/tjhunter/Documents/Mendeley Desktop/Hopcroft, Sheldon\_Unknown\_Manipulation-Resistant Reputations Using Hitting Time ∗.pdf:pdf},
number = {0514429},
title = {{Manipulation-Resistant Reputations Using Hitting Time ∗}}
}
@article{Ii,
author = {Ii, Part},
file = {:home/tjhunter/Documents/Mendeley Desktop/Ii\_Unknown\_Numerical mathematics.pdf:pdf},
title = {{Numerical mathematics}}
}
@article{Krishnamurthy2010,
archivePrefix = {arXiv},
arxivId = {arXiv:0908.0143v2},
author = {Krishnamurthy, Vijay},
eprint = {arXiv:0908.0143v2},
file = {:home/tjhunter/Documents/Mendeley Desktop/Krishnamurthy\_2010\_A Pathwise Algorithm for Covariance Selection.pdf:pdf},
pages = {1--12},
title = {{A Pathwise Algorithm for Covariance Selection}},
year = {2010}
}
@article{Mackey2012,
author = {Mackey, Lester},
file = {:home/tjhunter/Documents/Mendeley Desktop/Mackey\_2012\_Matrix Factorization and Matrix Concentration.pdf:pdf},
title = {{Matrix Factorization and Matrix Concentration}},
year = {2012}
}
@article{Morgan1996,
author = {Morgan, Ronald B},
file = {:home/tjhunter/Documents/Mendeley Desktop/Morgan\_1996\_LARGE NONSYMMETRIC EIGENVALUE PROBLEMS.pdf:pdf},
keywords = {and phrases,arnoldi,eigenvalues,krylov subspaces,nonsymmet-,sparse matrices},
number = {215},
pages = {1213--1230},
title = {{LARGE NONSYMMETRIC EIGENVALUE PROBLEMS}},
volume = {65},
year = {1996}
}
@article{Shewchuk1994,
author = {Shewchuk, Jonathan Richard},
file = {:home/tjhunter/Documents/Mendeley Desktop/Shewchuk\_1994\_An Introduction to the Conjugate Gradient Method Without the Agonizing Pain.pdf:pdf},
keywords = {1,2,5,agonizing pain,conjugate gradient method,convergence analysis,eigen do it if,eigenvalues,i try,jacobi iterations,preconditioning,thinking with eigenvectors and},
title = {{An Introduction to the Conjugate Gradient Method Without the Agonizing Pain}},
year = {1994}
}
@article{Tsiligkaridis,
archivePrefix = {arXiv},
arxivId = {arXiv:1204.0585v2},
author = {Tsiligkaridis, Theodoros and Member, Student and Iii, Alfred O Hero},
eprint = {arXiv:1204.0585v2},
file = {:home/tjhunter/Documents/Mendeley Desktop/Tsiligkaridis, Member, Iii\_Unknown\_Convergence Properties of Kronecker Graphical Lasso Algorithms.pdf:pdf},
pages = {1--59},
title = {{Convergence Properties of Kronecker Graphical Lasso Algorithms}}
}
@article{Yun2011,
author = {Yun, Sangwoon and Toh, Kim-chuan},
file = {:home/tjhunter/Documents/Mendeley Desktop/Yun, Toh\_2011\_A coordinate gradient descent method for \^{a}„“ 1-regularized convex minimization.pdf:pdf},
journal = {Computational Optimization and Applications},
keywords = {1 -regularization,com-,convex opti-,coordinate gradient descent,image deconvolution,linear least squares,logistic regression,pressed sensing,q-linear convergence},
pages = {1--39},
title = {{A coordinate gradient descent method for \^{a}„“ 1-regularized convex minimization}},
url = {http://www.springerlink.com/index/RN72K2Q5054R3214.pdf},
volume = {117576},
year = {2011}
}
@misc{,
file = {:home/tjhunter/Documents/Mendeley Desktop/Unknown\_Unknown\_SCAIM.pptx:pptx},
title = {{SCAIM}}
}
@article{Banerjee2008,
author = {Banerjee, Onureena},
file = {:home/tjhunter/Documents/Mendeley Desktop/Banerjee\_2008\_Model selection through sparse maximum likelihood estimation for multivariate gaussian or binary data.pdf:pdf},
journal = {The Journal of Machine \ldots},
keywords = {binary data,convex optimization,gaussian graphical model,maximum likelihood estimation,model selection},
pages = {1--35},
title = {{Model selection through sparse maximum likelihood estimation for multivariate gaussian or binary data}},
url = {http://dl.acm.org/citation.cfm?id=1390696},
year = {2008}
}
@article{Nadakuditi,
author = {Nadakuditi, Raj Rao and Silverstein, Jack W and Carolina, North},
file = {:home/tjhunter/Documents/Mendeley Desktop/Nadakuditi, Silverstein, Carolina\_Unknown\_Fundamental limit of sample eigenvalue based detection of signals in colored noise using relat.pdf:pdf},
pages = {1--7},
title = {{Fundamental limit of sample eigenvalue based detection of signals in colored noise using relatively few samples}}
}
@article{Seeger2009,
author = {Seeger, Matthias W},
doi = {10.1088/1742-6596/197/1/012001},
file = {:home/tjhunter/Documents/Mendeley Desktop/Seeger\_2009\_Sparse linear models Variational approximate inference and Bayesian experimental design.pdf:pdf},
issn = {1742-6596},
journal = {Journal of Physics: Conference Series},
month = dec,
pages = {012001},
title = {{Sparse linear models: Variational approximate inference and Bayesian experimental design}},
url = {http://stacks.iop.org/1742-6596/197/i=1/a=012001?key=crossref.6ed3d4640f5d393267fbbce8ca4f8a55},
volume = {197},
year = {2009}
}
@article{Alon1995,
abstract = {This paper investigates a zero-sum game played on a weighted connected graph G between two players, the tree player and the edge player. At each play, the tree player chooses a spanning tree T and the edge player chooses an edge e. The payoff to the edge player is \$\backslash textit\{cost\} (T, e)\$, defined as follows: If e lies in the tree T then \$\backslash textit\{cost\}(T, e) = 0\$; if e does not lie in the tree then \$\backslash textit\{cost\}(T, e) = cycle(T, e)/w(e)\$, where \$w(e)\$ is the weight of edge e and \$\backslash textit\{cycle\}(T, e)\$ is the weight of the unique cycle formed when edge e is added to the tree T. The main result is that the value of the game on any n-vertex graph is bounded above by \$\backslash exp(O(\backslash sqrt\{\backslash log n \backslash log \backslash log n\}))\$. It is conjectured that the value of the game is \$O(\backslash log n)\$. The game arises in connection with the k-server problem on a road network; i.e., a metric space that can be represented as a multigraph G in which each edge e represents a road of length \$w(e)\$. It is shown that, if the value of the game on G is \$\backslash textit\{Val\}(G, w)\$, then there is a randomized strategy that achieves a competitive ratio of \$k(1 + \backslash textit\{Val\}(G, w))\$ against any oblivious adversary. Thus, on any n-vertex road network, there is a randomized algorithm for the k-server problem that is \$k \backslash cdot \backslash exp(O(\backslash sqrt\{\backslash log n \backslash log \backslash log n\}))\$ competitive against oblivious adversaries. At the heart of the analysis of the game is an algorithm that provides an approximate solution for the simple network design problem. Specifically, for any n-vertex weighted, connected multigraph, the algorithm constructs a spanning tree T such that the average, over all edges e, of \$\backslash textit\{cost\}(T, e)\$ is less than or equal to \$\backslash exp(O(\backslash sqrt\{\backslash log n \backslash log \backslash log n\}))\$. This result has potential application to the design of communication networks. It also improves substantially known estimates concerning the existence of a sparse basis for the cycle space of a graph. Read More: http://epubs.siam.org/doi/abs/10.1137/S0097539792224474},
author = {Alon, Noga and Karp, RM and Peleg, D and West, Douglas},
doi = {10.1137/S0097539792224474},
file = {:home/tjhunter/Documents/Mendeley Desktop/Alon et al.\_1995\_A graph-theoretic game and its application to the k-server problem.pdf:pdf},
journal = {SIAM Journal on Computing},
number = {1},
pages = {78--100},
title = {{A graph-theoretic game and its application to the k-server problem}},
url = {http://epubs.siam.org/doi/abs/10.1137/S0097539792224474 http://epubs.siam.org/doi/pdf/10.1137/S0097539792224474},
volume = {24},
year = {1995}
}
@article{Bai1996,
author = {Bai, Zhaojun and Fahey, Mark and Golub, Gene H.},
doi = {10.1.1.56.8150},
file = {:home/tjhunter/Documents/Mendeley Desktop/Bai, Fahey, Golub\_1996\_Some large-scale matrix computation problems.pdf:pdf},
journal = {Journal of Computational and Applied \ldots},
number = {1},
pages = {71--89},
title = {{Some large-scale matrix computation problems}},
url = {http://www.sciencedirect.com/science/article/pii/0377042796000180},
volume = {74},
year = {1996}
}
@article{Barry1999,
author = {Barry, Ronald Paul and Pace, R. Kelley},
file = {:home/tjhunter/Documents/Mendeley Desktop/Barry, Pace\_1999\_Monte Carlo estimates of the log determinant of large sparse matrices.pdf:pdf},
journal = {Linear Algebra and its Applications},
title = {{Monte Carlo estimates of the log determinant of large sparse matrices}},
url = {http://www.sciencedirect.com/science/article/pii/S002437959710009X},
year = {1999}
}
@article{Cheng2001,
abstract = {The standard inverse scaling and squaring algorithm for computing the matrix logarithm begins by transforming the matrix to Schur triangular form in order to facilitate subsequent matrix square root and Pad ́ e approximation computations. A transformation-free form of this method that exploits incomplete Denman–Beavers square root iterations and aims for a specified accuracy (ignoring roundoff) is presented. The error introduced by using approximate square roots is accounted for by a novel splitting lemma for logarithms of matrix products. The number of square root stages and the degree of the final Pad ́ e approximation are chosen to minimize the computational work. This new method is attractive for high-performance computation since it uses only the basic building blocks of matrix multiplication, LU factorization and matrix inversion.},
author = {Cheng, Sheung Hun and Higham, Nicholas J. and Kenney, Charles S. and Laub, Alan J.},
doi = {10.1137/S0895479899364015},
file = {:home/tjhunter/Documents/Mendeley Desktop/Cheng et al.\_2001\_Approximating the Logarithm of a Matrix to Specified Accuracy.pdf:pdf},
issn = {08954798},
journal = {SIAM Journal on Matrix Analysis and Applications},
keywords = {Denman–Beavers iteration,Pade approximation,inverse scaling and squaring method,matrix logarithm,matrix square root},
number = {4},
pages = {1112},
title = {{Approximating the Logarithm of a Matrix to Specified Accuracy}},
url = {http://link.aip.org/link/SJMAEL/v22/i4/p1112/s1\&Agg=doi},
volume = {22},
year = {2001}
}
@article{Ipsen2006,
archivePrefix = {arXiv},
arxivId = {arXiv:1105.0437v1},
author = {Ipsen, Ilse C F and Lee, Dean J},
eprint = {arXiv:1105.0437v1},
file = {:home/tjhunter/Documents/Mendeley Desktop/Ipsen, Lee\_2006\_Determinant approximations(2).pdf:pdf},
journal = {Numerical Linear Algebra with Applications (under \ldots},
keywords = {15a15,15a18,15a42,15a90,65f40,ams subject classifications,determinant,expansion,lattice simulation,sparse approximate inverse,spectral radius,trace,zone determinant},
number = {X},
title = {{Determinant approximations}},
url = {http://www.ncsu.edu/crsc/reports/ftp/pdf/crsc-tr03-30.pdf},
year = {2006}
}
@article{Ipsen2006a,
abstract = {A sequence of approximations for the determinant of a complex matrix is derived, along with relative error bounds. The first approximation in this sequence represents an extension of Fischer’s and Hadamard’s inequalities to indefinite non-Hermitian matrices. The approximations are based on expansions of det(X) = exp(trace(log(X))).},
author = {Ipsen, Ilse C. F. and Lee, Dean J.},
file = {:home/tjhunter/Documents/Mendeley Desktop/Ipsen, Lee\_2006\_Determinant approximations.pdf:pdf},
journal = {Numerical Linear Algebra with Applications (under \ldots},
keywords = {determinant,determinantal inequalities,spectral radius,trace,tridiagonal matrix},
number = {X},
title = {{Determinant approximations}},
url = {http://www.ncsu.edu/crsc/reports/ftp/pdf/crsc-tr03-30.pdf},
year = {2006}
}
@article{Li2000a,
author = {Li, CK and Mathias, Roy},
file = {:home/tjhunter/Documents/Mendeley Desktop/Li, Mathias\_2000\_Extremal Characterizations of the Schur Complement and Resulting Inequalities.pdf:pdf},
journal = {SIAM Review},
pages = {1--15},
title = {{Extremal characterizations of the Schur complement and resulting inequalities}},
url = {http://www.jstor.org/stable/10.2307/2653106},
year = {2000}
}
@article{Foygel,
archivePrefix = {arXiv},
arxivId = {arXiv:1106.4251v1},
author = {Foygel, Rina and Srebro, Nathan},
eprint = {arXiv:1106.4251v1},
file = {:home/tjhunter/Documents/Mendeley Desktop/Foygel, Srebro\_Unknown\_Sampling Distributions.pdf:pdf},
title = {{Sampling Distributions}}
}
@article{Harvey2011,
author = {Harvey, Prof Nick},
file = {:home/tjhunter/Documents/Mendeley Desktop/Harvey\_2011\_Lecture 12.pdf:pdf},
number = {1},
pages = {1--2},
title = {{Lecture 12}},
year = {2011}
}
@article{Indulal2009,
author = {Indulal, G.},
doi = {10.1016/j.laa.2008.07.005},
file = {:home/tjhunter/Documents/Mendeley Desktop/Indulal\_2009\_Sharp bounds on the distance spectral radius and the distance energy of graphs.pdf:pdf},
issn = {00243795},
journal = {Linear Algebra and its Applications},
keywords = {distance energy,distance spectral radius},
month = jan,
number = {1},
pages = {106--113},
publisher = {Elsevier Inc.},
title = {{Sharp bounds on the distance spectral radius and the distance energy of graphs}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S002437950800339X},
volume = {430},
year = {2009}
}
@article{Papandreoua,
archivePrefix = {arXiv},
arxivId = {arXiv:1107.4637v2},
author = {Papandreou, George and Yuille, Alan L},
eprint = {arXiv:1107.4637v2},
file = {:home/tjhunter/Documents/Mendeley Desktop/Papandreou, Yuille\_Unknown\_Efficient Variational Inference in Large-Scale Bayesian Compressed Sensing.pdf:pdf},
title = {{Efficient Variational Inference in Large-Scale Bayesian Compressed Sensing}}
}
@article{Saad1994,
author = {Saad, Y},
file = {:home/tjhunter/Documents/Mendeley Desktop/Saad\_1994\_Theoretical error bounds and general analysis of a few Lanczos-type algorithms.pdf:pdf},
journal = {Brown et al.[BCEP94]},
title = {{Theoretical error bounds and general analysis of a few Lanczos-type algorithms}},
url = {http://books.google.com/books?hl=en\&lr=\&id=XzVHBJ1zOAAC\&oi=fnd\&pg=PA123\&dq=Theoretical+error+bounds+and+general+analysis+of+a+few+lanczos-type+algorithms\&ots=TMH2sbmoCd\&sig=yeJ282AeaBOn4L1bD2GnseRRKTA},
year = {1994}
}
@article{Tao1991,
archivePrefix = {arXiv},
arxivId = {arXiv:1201.4789v3},
author = {Tao, Terence and Vu, V A N},
eprint = {arXiv:1201.4789v3},
file = {:home/tjhunter/Documents/Mendeley Desktop/Tao, Vu\_1991\_Random matrices sharp concentration of eigenvalues.pdf:pdf},
pages = {1--27},
title = {{Random matrices: sharp concentration of eigenvalues}},
year = {1991}
}
@article{Chen2012a,
author = {Chen, Bo},
file = {:home/tjhunter/Documents/Mendeley Desktop/Chen\_2012\_Joint Optimization and Variable Selection of High-dimensional Gaussian Processes.pdf:pdf},
journal = {Arxiv preprint arXiv:1206.6396},
title = {{Joint Optimization and Variable Selection of High-dimensional Gaussian Processes}},
url = {http://arxiv.org/abs/1206.6396},
year = {2012}
}
@article{Contents2012,
author = {Contents, Heterocycles},
doi = {10.3987/Contents-12-85-7},
file = {:home/tjhunter/Documents/Mendeley Desktop/Contents\_2012\_Contents.pdf:pdf},
issn = {0385-5414},
journal = {Heterocycles},
number = {7},
pages = {25},
title = {{Contents}},
url = {http://www.heterocycles.jp/newlibrary/libraries/abst/22753},
volume = {85},
year = {2012}
}
@article{Davies2003,
author = {Davies, Philip I and Higham, Nicholas J},
file = {:home/tjhunter/Documents/Mendeley Desktop/Davies, Higham\_2003\_A Schur--Parlett Algorithm for Computing Matrix Functions.pdf:pdf},
keywords = {1,65f30,ams subject classifications,and engineer-,diverse role in science,introduction,lapack,matlab,matrix cosine,matrix exponential,matrix function,matrix functions play a,matrix logarithm,parlett recurrence,schur decomposition,sep function,series,taylor},
number = {March},
title = {{A Schur--Parlett Algorithm for Computing Matrix Functions}},
url = {http://eprints.ma.man.ac.uk/156/},
year = {2003}
}
@article{Kenney1998,
author = {Kenney, C S and Laub, A J},
file = {:home/tjhunter/Documents/Mendeley Desktop/Kenney, Laub\_1998\_ALGORITHM FOR COMPUTING THE LOGARITHM AND EXPONENTIAL OF A MATRIX.pdf:pdf},
keywords = {15a12,15a24,65-04,65d20,65f35,ams subject classifications,matrix exponential,matrix functions,matrix logarithm,pii,s0895479896300334},
number = {3},
pages = {640--663},
title = {{ALGORITHM FOR COMPUTING THE LOGARITHM AND EXPONENTIAL OF A MATRIX}},
volume = {19},
year = {1998}
}
@article{Lu,
archivePrefix = {arXiv},
arxivId = {arXiv:1111.4541v2},
author = {Lu, Nguyen and Khoa, Dang},
eprint = {arXiv:1111.4541v2},
file = {:home/tjhunter/Documents/Mendeley Desktop/Lu, Khoa\_Unknown\_Large Scale Spectral Clustering Using Approximate Commute Time Embedding.pdf:pdf},
keywords = {commute time embed-,ding,linear time solver,random projection,spectral clustering},
title = {{Large Scale Spectral Clustering Using Approximate Commute Time Embedding}}
}
@article{Orecchiaa,
archivePrefix = {arXiv},
arxivId = {arXiv:1111.1491v1},
author = {Orecchia, Lorenzo},
eprint = {arXiv:1111.1491v1},
file = {:home/tjhunter/Documents/Mendeley Desktop/Orecchia\_Unknown\_Approximating the Exponential , the Lanczos Method and ˜ ( m ) -Time Spectral Algorithm for Balanced Separator.pdf:pdf},
keywords = {balanced graph partitioning,lanczos,matrix exponential,method,spectral algorithms,uniform approximation},
title = {{Approximating the Exponential , the Lanczos Method and ˜ ( m ) -Time Spectral Algorithm for Balanced Separator}}
}
@article{Spielman2008,
abstract = {Abstract We study the design of local algorithms for massive graphs. A local algorithm is one that ﬁnds a solution containing or near a given vertex without looking at the whole graph. We present a local clustering algorithm. Our algorithm ﬁnds a good cluster—a subset of vertices whose internal connections are signiﬁcantly richer than its external connections— near a given vertex. The running time of our algorithm, when it ﬁnds a non-empty local cluster, is nearly linear in the size of the cluster it outputs. Our clustering algorithm could be a useful primitive for handling massive graphs, such as social networks and web-graphs. As an application of this clustering algorithm, we present a partitioning algorithm that ﬁnds an approximate sparsest cut with nearly optimal balance. Our algorithm takes time nearly linear in the number edges of the graph. Using the partitioning algorithm of this paper, we have designed a nearly-linear time algorithm for constructing spectral sparsiﬁers of graphs, which we in turn use in a nearly- linear time algorithm for solving linear systems in symmetric, diagonally-dominant matrices. The linear system solver also leads to a nearly linear-time algorithm for approximating the second-smallest eigenvalue and corresponding eigenvector of the Laplacian matrix of a graph. These other results are presented in two companion papers.},
archivePrefix = {arXiv},
arxivId = {arXiv:0809.3232v1},
author = {Spielman, Daniel A and Teng, Shang-Hua},
eprint = {arXiv:0809.3232v1},
file = {:home/tjhunter/Documents/Mendeley Desktop/Spielman, Teng\_2008\_A Local Clustering Algorithm for Massive Graphs and its Application to Nearly-Linear Time Graph Partitioning.pdf:pdf},
title = {{A Local Clustering Algorithm for Massive Graphs and its Application to Nearly-Linear Time Graph Partitioning}},
year = {2008}
}
@article{Subgraphs,
archivePrefix = {arXiv},
arxivId = {arXiv:1111.1750v1},
author = {Subgraphs, Low-stretch and Blelloch, Guy E and Peng, Richard and Miller, Gary L and Nov, D S},
eprint = {arXiv:1111.1750v1},
file = {:home/tjhunter/Documents/Mendeley Desktop/Subgraphs et al.\_Unknown\_Near Linear-Work Parallel SDD Solvers , Low-Diameter.pdf:pdf},
pages = {1--23},
title = {{Near Linear-Work Parallel SDD Solvers , Low-Diameter}}
}
@article{Sudderth2002,
author = {Sudderth, Erik B},
file = {:home/tjhunter/Documents/Mendeley Desktop/Sudderth\_2002\_Embedded Trees Estimation of Gaussian by.pdf:pdf},
title = {{Embedded Trees : Estimation of Gaussian by}},
year = {2002}
}
@article{Tao2011,
author = {Tao, Terence},
file = {:home/tjhunter/Documents/Mendeley Desktop/Tao\_2011\_Topics in random matrix theory.pdf:pdf},
journal = {American Mathematical Society.(to appear)},
title = {{Topics in random matrix theory}},
url = {http://www.ams.org/bookstore-getitem/item=GSM-132},
year = {2011}
}
@article{Varun,
author = {Varun, Su-in Lee and Daphne, Ganapathi},
file = {:home/tjhunter/Documents/Mendeley Desktop/Varun, Daphne\_Unknown\_Efficient Structure Learning of Markov Networks using L 1 -Regularization.pdf:pdf},
number = {Ml},
title = {{Efficient Structure Learning of Markov Networks using L 1 -Regularization}}
}
@article{liu1990eliminationtrees,
author = {Liu, J},
doi = {10.1137/0611010},
journal = {SIAM Journal on Matrix Analysis and Applications},
number = {1},
pages = {134--172},
title = {{The Role of Elimination Trees in Sparse Factorization}},
url = {http://epubs.siam.org/doi/abs/10.1137/0611010},
volume = {11},
year = {1990}
}
@article{Malioutov2008a,
author = {Malioutov, Dmitry M and Science, Computer and Willsky, Alan S and Supervisor, Thesis and Orlando, Terry P},
file = {:home/tjhunter/Documents/Mendeley Desktop/Malioutov et al.\_2008\_Approximate Inference in Gaussian Graphical Models.pdf:pdf},
title = {{Approximate Inference in Gaussian Graphical Models}},
year = {2008}
}
@article{martin1992approximations,
author = {Martin, R J},
journal = {Communications in Statistics-Theory and Methods},
number = {1},
pages = {189--205},
publisher = {Taylor \& Francis},
title = {{Approximations to the determinant term in Gaussian maximum likelihood estimation of some spatial models}},
volume = {22},
year = {1992}
}
@article{McCourt2008,
abstract = {The efficacy of approximation by radial basis functions is often determined by a scale parameter $\sigma$. Unfortunately, some choices of $\sigma$ which will produce a good interpolant yield an ill-conditioned matrix. One method of choosing an appropriate scale parameter is to assume the data is a realization of a Gaussian process and then find the maximum likelihood estimator. This will require the evaluation of the determinant of the covariance matrix; doing so will likely be an ill-conditioned problem because of the spectrum of the covariance matrix. Here we will discuss a Monte Carlo technique developed in [7] and analyze its usefulness on matrices arising in radial basis approximation. Later we will consider an adaptation of this method which will be applicable to more general matrices.},
author = {McCourt, M},
file = {:home/tjhunter/Documents/Mendeley Desktop/McCourt\_2008\_A Stochastic Simulation for Approximating the log-Determinant of a Symmetric Positive Definite Matrix.pdf:pdf},
journal = {compare},
pages = {1--10},
title = {{A Stochastic Simulation for Approximating the log-Determinant of a Symmetric Positive Definite Matrix}},
url = {http://www.thefutureofmath.com/mathed/logdet.pdf},
volume = {2},
year = {2008}
}
@book{meurant1999computer,
author = {Meurant, G\'{e}rard A},
publisher = {North-Holland: Amsterdam},
title = {{Computer Solution of Large Linear Systems}},
year = {1999}
}
@incollection{meurant1999131,
author = {Meurant, G\'{e}rard A},
booktitle = {Computer Solution of Large Linear Systems},
chapter = {3},
doi = {http://dx.doi.org/10.1016/S0168-2024(99)80004-6},
editor = {Meurant, Gerard},
issn = {0168-2024},
pages = {131--176},
publisher = {Elsevier},
series = {Studies in Mathematics and Its Applications},
title = {{3 Gaussian elimination for sparse linear systems}},
url = {http://www.sciencedirect.com/science/article/pii/S0168202499800046},
volume = {28},
year = {1999}
}
@article{Morozov2011,
archivePrefix = {arXiv},
arxivId = {arXiv:0804.4632v3},
author = {Morozov, A and Shakirov, Sh},
eprint = {arXiv:0804.4632v3},
file = {:home/tjhunter/Documents/Mendeley Desktop/Morozov, Shakirov\_2011\_Analogue of the identity Log Det= Trace Log for resultants.pdf:pdf},
journal = {Journal of Geometry and Physics},
title = {{Analogue of the identity Log Det= Trace Log for resultants}},
url = {http://www.sciencedirect.com/science/article/pii/S0393044010002445},
volume = {2},
year = {2011}
}
@article{Reusken2002,
abstract = {This paper is concerned with the problem of approximating det(A)\^{}1/n for a large sparse symmetric positive definite matrix A of order n. It is shown that an effcient solution of this problem is obtained by using a sparse approximate inverse of A. The method is explained and theoretical properties are discussed. A posteriori error estimation techniques are presented. Furthermore, results of numerical experiments are given which illustrate the performance of this new method.},
author = {Reusken, Arnold},
doi = {10.1137/S089547980036869X},
file = {:home/tjhunter/Documents/Mendeley Desktop/Reusken\_2002\_Approximation of the Determinant of Large Sparse Symmetric Positive Definite Matrices.pdf:pdf},
issn = {08954798},
journal = {SIAM Journal on Matrix Analysis and Applications},
keywords = {determinant,preconditioning,sparse approximate inverse},
number = {3},
pages = {799},
title = {{Approximation of the Determinant of Large Sparse Symmetric Positive Definite Matrices}},
url = {http://link.aip.org/link/SJMAEL/v23/i3/p799/s1\&Agg=doi},
volume = {23},
year = {2002}
}
@unpublished{Reusken2000,
abstract = {This paper is concerned with the problem of approximating det(A)\^{}1/n for a large sparse symmetric positive definite matrix A of order n. It is shown that an efficient solution of this problem is obtained by using a sparse approximate inverse of A. The method is explained and theoretical properties are discussed. The method is ideal for implementation on a parallel computer. Numerical experiments are described that illustrate the performance of this new method and provide a comparison with Monte Carlo–type methods from the literature.},
author = {Reusken, Arnold},
booktitle = {Arxiv preprint hep-lat/0008007},
file = {:home/tjhunter/Documents/Mendeley Desktop/Reusken\_2000\_Approximation of the determinant of large sparse symmetric positive definite matrices.pdf:pdf},
keywords = {1,65f10,65f50,6f10,a denotes a real,ams subject classifications,determinant,introduction,pii,preconditioning,s089547980036869x,sparse approximate inverse,symmetric positive,throughout this paper},
mendeley-tags = {determinant,preconditioning,sparse approximate inverse},
number = {3},
pages = {799--818},
title = {{Approximation of the determinant of large sparse symmetric positive definite matrices}},
url = {http://arxiv.org/abs/hep-lat/0008007},
volume = {23},
year = {2000}
}
@article{Silvester2000,
author = {Silvester, John R.},
doi = {10.2307/3620776},
file = {:home/tjhunter/Documents/Mendeley Desktop/Silvester\_2000\_Determinants of Block Matrices.pdf:pdf},
issn = {00255572},
journal = {The Mathematical Gazette},
month = nov,
number = {501},
pages = {460},
title = {{Determinants of Block Matrices}},
url = {http://www.jstor.org/stable/3620776?origin=crossref},
volume = {84},
year = {2000}
}
@article{Wainwright2006,
author = {Wainwright, M.J. and Jordan, M.I.},
doi = {10.1109/TSP.2006.874409},
file = {:home/tjhunter/Documents/Mendeley Desktop/Wainwright, Jordan\_2006\_Log-determinant relaxation for approximate inference in discrete Markov random fields.pdf:pdf},
issn = {1053-587X},
journal = {IEEE Transactions on Signal Processing},
month = jun,
number = {6},
pages = {2099--2109},
title = {{Log-determinant relaxation for approximate inference in discrete Markov random fields}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1634807},
volume = {54},
year = {2006}
}
@article{Wang2010,
author = {Wang, Chengjing},
file = {:home/tjhunter/Documents/Mendeley Desktop/Wang\_2010\_Solving log-determinant optimization problems by a Newton-CG primal proximal point algorithm(2).pdf:pdf},
journal = {SIAM Journal on Optimization},
keywords = {log-determinant optimization problem,newton,proximal-point algorithm,s method,sparse inverse covariance selec-,tion},
pages = {1--24},
title = {{Solving log-determinant optimization problems by a Newton-CG primal proximal point algorithm}},
url = {http://www.math.nus.edu.sg/~matsundf/logdet-NAL-29Sep09.pdf},
volume = {117543},
year = {2010}
}
@article{Zhang2007,
abstract = {Maximum likelihood estimation of hyperparameters in Gaussian processes (GPs) as well as other spatial regression models usually requires the evaluation of the logarithm of the matrix determinant, in short, log det. When using matrix decomposition techniques, the exact implementation of log det 3is of O(N ) operations, where N is the matrix dimension. In this paper, a power-series expansion- based framework is presented for approximating the log det of general positive-definite matrices. Three novel compensation schemes are proposed to further improve the approximation accuracy and 2computational efficiency. The proposed log det approximation requires only 50N operations. The theoretical analysis is substantiated by a large number of numerical experiments, including tests on randomly generated positive-definite matrices, randomly generated covariance matrices, and sequences of covariance matrices generated online in two GP regression examples. The average approximation error is ∼9\%.},
author = {Zhang, Y. and Leithead, W. E.},
doi = {10.1080/10629360600569279},
file = {:home/tjhunter/Documents/Mendeley Desktop/Zhang, Leithead\_2007\_Approximate implementation of the logarithm of the matrix determinant in Gaussian process regression.pdf:pdf},
issn = {0094-9655},
journal = {Journal of Statistical Computation and Simulation},
keywords = {Compensation,Gaussian process,Logarithm of matrix determinant,Power-series expansion},
month = apr,
number = {4},
pages = {329--348},
title = {{Approximate implementation of the logarithm of the matrix determinant in Gaussian process regression}},
url = {http://www.tandfonline.com/doi/abs/10.1080/10629360600569279},
volume = {77},
year = {2007}
}
@article{Zhang2008,
abstract = {Maximum likelihood estimation (MLE) of hyperparameters in Gaussian process regression as well as other computational models usuallyandfrequently requires the evaluation of the logarithm of the determinant of a positive-definite matrix (denoted by C hereafter). In general, the exact computation of log det C is of O(N3) operations where N is the matrix dimension. The approximation of log det C could be developed with O(N2) operations based on power-series expansion and randomized trace estimator. In this paper, the accuracy and effectiveness of using uniformly distributed seeds for log det C approximation are investigated. The research shows that uniform-seed based approximation is an equally good alternative to Gaussian-seed based approximation, having slightly better approximation accuracy and smaller variance. Gaussian process regression examples also substantiate the effectiveness of such a uniform-seed based log-det approximation scheme.},
author = {Zhang, Yunong and Leithead, W.E. and Leith, D.J. and Walshe, L.},
doi = {10.1016/j.cam.2007.08.012},
file = {:home/tjhunter/Documents/Mendeley Desktop/Zhang et al.\_2008\_Log-det approximation based on uniformly distributed seeds and its application to Gaussian process regression.pdf:pdf},
issn = {03770427},
journal = {Journal of Computational and Applied Mathematics},
keywords = {gaussian random seeds,log-det approximation,n 2,o,operations,randomized trace estimator,uniformly distributed seeds},
month = oct,
number = {1-2},
pages = {198--214},
title = {{Log-det approximation based on uniformly distributed seeds and its application to Gaussian process regression}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0377042707004360},
volume = {220},
year = {2008}
}
@article{Chen2012,
archivePrefix = {arXiv},
arxivId = {arXiv:1201.6002v1},
author = {Chen, Richard Y and Farrell, Brendan and Tropp, Joel A and Jan, P R},
eprint = {arXiv:1201.6002v1},
file = {:home/tjhunter/Documents/Mendeley Desktop/Chen et al.\_2012\_Matrix concentration inequalities via the method of exchangeable pairs.pdf:pdf},
number = {January},
pages = {1--29},
title = {{Matrix concentration inequalities via the method of exchangeable pairs}},
year = {2012}
}
@article{Kapralov,
author = {Kapralov, Michael and Panigrahy, Rina},
file = {:home/tjhunter/Documents/Mendeley Desktop/Kapralov, Panigrahy\_Unknown\_Spectral sparsification via random spanners Extended Abstract.pdf:pdf},
isbn = {9781450311151},
title = {{Spectral sparsification via random spanners [ Extended Abstract ]}},
volume = {1}
}
@article{Ng2001,
author = {Ng, AY},
file = {:home/tjhunter/Documents/Mendeley Desktop/Ng\_2001\_Link analysis, eigenvectors and stability.pdf:pdf},
journal = {International Joint Conference on Artificial \ldots},
title = {{Link analysis, eigenvectors and stability}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.81.899\&rep=rep1\&type=pdf},
year = {2001}
}
@article{Ravikumar2011,
author = {Ravikumar, Pradeep and Wainwright, Martin J. and Raskutti, Garvesh and Yu, Bin},
doi = {10.1214/11-EJS631},
file = {:home/tjhunter/Documents/Mendeley Desktop/Ravikumar et al.\_2011\_High-dimensional covariance estimation by minimizing ℓ 1 -penalized log-determinant divergence.pdf:pdf},
issn = {1935-7524},
journal = {Electronic Journal of Statistics},
keywords = {62F12, 62F30, Covariance, concentration, precision},
number = {January 2010},
pages = {935--980},
title = {{High-dimensional covariance estimation by minimizing ℓ 1 -penalized log-determinant divergence}},
url = {http://projecteuclid.org/euclid.ejs/1316092865},
volume = {5},
year = {2011}
}
@phdthesis{Rouet2009,
author = {Rouet, Fran\c{c}ois-Henry},
file = {:home/tjhunter/Documents/Mendeley Desktop/Rouet\_2009\_Partial computation of the inverse of a large sparse matrix - application to astrophysics.pdf:pdf},
title = {{Partial computation of the inverse of a large sparse matrix - application to astrophysics}},
year = {2009}
}
@techreport{Wong2003,
author = {Wong, Frederick},
booktitle = {Biometrika},
file = {:home/tjhunter/Documents/Mendeley Desktop/Wong\_2003\_Efficient estimation of covariance selection models.pdf:pdf},
title = {{Efficient estimation of covariance selection models}},
url = {http://biomet.oxfordjournals.org/content/90/4/809.short},
year = {2003}
}
@article{,
file = {:home/tjhunter/Documents/Mendeley Desktop/Unknown\_Unknown\_Chapter 2 Eigenvalue a n d Singular Value Inequalities of Schur C o m p l e m e n t s.pdf:pdf},
title = {{Chapter 2 Eigenvalue a n d Singular Value Inequalities of Schur C o m p l e m e n t s}}
}
@article{Andersen2008,
archivePrefix = {arXiv},
arxivId = {arXiv:0811.3779v1},
author = {Andersen, Reid and Peres, Yuval},
eprint = {arXiv:0811.3779v1},
file = {:home/tjhunter/Documents/Mendeley Desktop/Andersen, Peres\_2008\_Finding Sparse Cuts Locally Using Evolving Sets.pdf:pdf},
title = {{Finding Sparse Cuts Locally Using Evolving Sets}},
year = {2008}
}
@article{Avron2010,
author = {Avron, Haim and Toledo, Sivan},
file = {:home/tjhunter/Documents/Mendeley Desktop/Avron, Toledo\_2010\_RANDOMIZED ALGORITHMS FOR ESTIMATING THE TRACE OF AN IMPLICIT SYMMETRIC POSITIVE SEMI-DEFINITE MATRIX random variabl.pdf:pdf},
number = {2},
title = {{RANDOMIZED ALGORITHMS FOR ESTIMATING THE TRACE OF AN IMPLICIT SYMMETRIC POSITIVE SEMI-DEFINITE MATRIX random variables ( Pr ( z i = ± 1 ) = 1 / 2 ). z T Az is an unbiased estimator of trace ( A ) i . e .,}},
year = {2010}
}
@article{Banerjee2006,
archivePrefix = {arXiv},
arxivId = {arXiv:math/0609812v1},
author = {Banerjee, Onureena and Ghaoui, Laurent E L},
eprint = {0609812v1},
file = {:home/tjhunter/Documents/Mendeley Desktop/Banerjee, Ghaoui\_2006\_First-order methods for sparse covariance selection.pdf:pdf},
pages = {1--11},
primaryClass = {arXiv:math},
title = {{First-order methods for sparse covariance selection}},
year = {2006}
}
@article{ChafaA±2006,
author = {Chafa\"{A}±, D and Concordet, D},
file = {:home/tjhunter/Documents/Mendeley Desktop/Chafa\"{A}±, Concordet\_2006\_Covariance matrices with prescribed null entries.pdf:pdf},
journal = {djalil.chafai.net},
number = {May},
pages = {1--17},
title = {{Covariance matrices with prescribed null entries}},
url = {http://djalil.chafai.net/Docs/posmatrix.pdf},
year = {2006}
}
@incollection{ElGhaoui2008,
author = {{El Ghaoui}, Laurent},
file = {:home/tjhunter/Documents/Mendeley Desktop/El Ghaoui\_2008\_Lecture 13 SDP Duality Direct approach.pdf:pdf},
pages = {1--6},
title = {{Lecture 13 : SDP Duality Direct approach}},
year = {2008}
}
@article{Garc2004,
archivePrefix = {arXiv},
arxivId = {arXiv:cs/0412107v2},
author = {Garc, L A},
eprint = {0412107v2},
file = {:home/tjhunter/Documents/Mendeley Desktop/Garc\_2004\_A Monte Carlo algorithm for efficient large matrix inversion.pdf:pdf},
journal = {Arxiv preprint cs/0412107},
keywords = {gibbs sampler,inverse matrix,monte carlo,sparse matrices},
pages = {1--13},
primaryClass = {arXiv:cs},
title = {{A Monte Carlo algorithm for efficient large matrix inversion}},
url = {http://arxiv.org/abs/cs/0412107},
year = {2004}
}
@article{Golub,
author = {Golub, Gene H. and Liao, Li-Zhi},
file = {:home/tjhunter/Documents/Mendeley Desktop/Golub, Liao\_Unknown\_A Continuous Method for Extreme Eigenvalue Problems.pdf:pdf},
journal = {Citeseer},
title = {{A Continuous Method for Extreme Eigenvalue Problems}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.10.2224}
}
@article{Koutis2011,
archivePrefix = {arXiv},
arxivId = {arXiv:1102.4842v4},
author = {Koutis, Ioannis and Miller, Gary L and Peng, Richard},
eprint = {arXiv:1102.4842v4},
file = {:home/tjhunter/Documents/Mendeley Desktop/Koutis, Miller, Peng\_2011\_A nearly-m log n time solver for SDD linear systems.pdf:pdf},
pages = {1--16},
title = {{A nearly-m log n time solver for SDD linear systems}},
year = {2011}
}
@article{Koutisa,
abstract = {We present an algorithm that on input of an n-vertex m-edge weighted graph G and a value k, produces an incremental ˆ sparsiﬁer G with n−1+m/k edges, such that the condition number ˆ ˜ of G with G is bounded above by O(k log2 n), with probability 1 − p. The algorithm runs in time ˜ O((m log n + n log2 n) log(1/p)). As a result, we obtain an algorithm that on input of an n × n symmetric diagonally dominant matrix A with m non-zero entries and a vector b, computes a vector x satisfying ||x − A+ b||A < ||A+ b||A , in expected time ˜ O(m log2 n log(1/ )). The solver is based on repeated applications of the incremental sparsiﬁer that produces a chain of graphs which is then used as input to a recursive preconditioned Chebyshev iteration.},
author = {Koutis, Ioannis and Miller, Gary L. and Peng, Richard},
doi = {10.1109/FOCS.2010.29},
file = {:home/tjhunter/Documents/Mendeley Desktop/Koutis, Miller, Peng\_2010\_Approaching Optimality for Solving SDD Linear Systems.pdf:pdf},
isbn = {978-1-4244-8525-3},
journal = {2010 IEEE 51st Annual Symposium on Foundations of Computer Science},
keywords = {algorithms,combinatorial preconditioning,linear systems,spectral graph theory},
month = oct,
pages = {235--244},
publisher = {Ieee},
title = {{Approaching Optimality for Solving SDD Linear Systems}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=567},
year = {2010}
}
@article{Malioutov2008,
author = {Malioutov, Dmitry M and Member, Student and Johnson, Jason K and Choi, Myung Jin and Willsky, Alan S},
file = {:home/tjhunter/Documents/Mendeley Desktop/Malioutov et al.\_2008\_Low-Rank Variance Approximation in GMRF Models Single and Multiscale Approaches.pdf:pdf},
number = {10},
pages = {4621--4634},
title = {{Low-Rank Variance Approximation in GMRF Models : Single and Multiscale Approaches}},
volume = {56},
year = {2008}
}
@article{Mascagni2000,
author = {Mascagni, Michael and Karaivanova, Aneta},
file = {:home/tjhunter/Documents/Mendeley Desktop/Mascagni, Karaivanova\_2000\_A parallel quasi-monte carlo method for computing extremal eigenvalues.pdf:pdf},
journal = {\ldots Carlo and Quasi-Monte Carlo \ldots},
keywords = {chains,eigenvalues,markov,monte carlo methods,parallel computing,parallel efficiency,quasi-monte carlo methods},
pages = {1--14},
title = {{A parallel quasi-monte carlo method for computing extremal eigenvalues}},
url = {http://websrv.cs.fsu.edu/~mascagni/papers/RICP2001\_3.pdf},
year = {2000}
}
@article{Miroslav,
author = {Miroslav, T},
file = {:home/tjhunter/Documents/Mendeley Desktop/Miroslav\_Unknown\_Direct Methods for Sparse Matrices.pdf:pdf},
title = {{Direct Methods for Sparse Matrices}}
}
@article{Papandreou,
author = {Papandreou, George and Yuille, Alan L},
file = {:home/tjhunter/Documents/Mendeley Desktop/Papandreou, Yuille\_Unknown\_Gaussian sampling by local perturbations.pdf:pdf},
pages = {1--9},
title = {{Gaussian sampling by local perturbations}}
}
@article{Sarma,
archivePrefix = {arXiv},
arxivId = {arXiv:1201.1363v2},
author = {Sarma, Atish Das},
eprint = {arXiv:1201.1363v2},
file = {:home/tjhunter/Documents/Mendeley Desktop/Sarma\_Unknown\_Near-Optimal Random Walk Sampling in Distributed Networks.pdf:pdf},
keywords = {anisurpm,atish,com,dassarma,decentralized computation,distributed algorithms,division of mathematical sciences,e-mail,gmail,google inc,google research,gopalpandurangan,m58110000,mountain view,nanyang technological university,nanyang technological university grant,random sampling,random walks,singapore 637371 e-mail,supported in part by,usa},
title = {{Near-Optimal Random Walk Sampling in Distributed Networks}}
}
@article{Spielman2009a,
abstract = {We present a randomized algorithm that, on input a symmetric, weakly diagonally dominant \$n\$-by-\$n\$ matrix \$A\$ with \$m\$ non-zero entries and an \$n\$-vector \$\backslash bb\$, produces an \$\backslash xxtil \$ such that \$\backslash norm\{\backslash xx - \backslash xxtil\}\_\{A\} \backslash leq \backslash epsilon \backslash norm\{\backslash xx\}\_\{A\}\$, where \$A\backslash xx=\backslash bb\$, in expected time \$m \backslash log\^{}\{O (1)\}n \backslash log (1/\backslash epsilon)\$. The algorithm applies subgraph preconditioners in a recursive fashion. These preconditioners improve upon the subgraph preconditioners first introduced by Vaidya (1990). For any symmetric, weakly diagonally-dominant matrix \$A\$ with non-positive off-diagonal entries and \$k \backslash geq 1\$, we construct in time \$m \backslash log\^{}\{O (1)\} n\$ a preconditioner of \$A\$ with at most \$2 (n - 1+ k)\$ non-zero off-diagonal entries such that the preconditioned system has condition number at most \$(n/k) \backslash log\^{}\{O (1)\} n\$. If the non-zero structure of the matrix is planar, then the condition number is at most \$(n/k) \backslash log\^{}\{2\} n \backslash log \backslash log n\$, and the corresponding linear system solver runs in expected time \$O (n \backslash log\^{}\{2\} n \backslash log \backslash log n \backslash log (1/\backslash epsilon))\$. Similar bounds are obtained on the running time of algorithms computing approximate Fiedler vectors.},
archivePrefix = {arXiv},
arxivId = {arXiv:cs/0607105v4},
author = {Spielman, Daniel A and Teng, Shang-Hua},
eprint = {0607105v4},
file = {:home/tjhunter/Documents/Mendeley Desktop/Spielman, Teng\_2009\_Nearly-Linear Time Algorithms for Preconditioning and Solving Symmetric , Diagonally Dominant Linear Systems.pdf:pdf},
pages = {1--48},
primaryClass = {arXiv:cs},
title = {{Nearly-Linear Time Algorithms for Preconditioning and Solving Symmetric , Diagonally Dominant Linear Systems}},
year = {2009}
}
@article{,
file = {:home/tjhunter/Documents/Mendeley Desktop/Unknown\_1998\_Parallel computations of eigenvalues based on a Monte Carlo approach.ps:ps},
journal = {Monte Carlo Methods and Applications},
title = {{Parallel computations of eigenvalues based on a Monte Carlo approach}},
url = {http://parallel.bas.bg/dpa/BG/dimov/MyPapers/98DK.ps},
year = {1998}
}
@article{Zi-zong2009,
author = {Zi-zong, Yan},
doi = {10.7153/jmi-03-16},
file = {:home/tjhunter/Documents/Mendeley Desktop/Zi-Zong\_2009\_Schur Complements and Determinant Inequalities.pdf:pdf},
issn = {1846-579X},
journal = {Journal of Mathematical Inequalities},
keywords = {70771080,and phrases,china,fischer inequality,hadamard inequality,hua loo-keng,inequality,koteljanski inequality,natural science foundation of,schur complement,supported by the national},
number = {2},
pages = {161--167},
title = {{Schur complements and determinant inequalities}},
url = {http://jmi.ele-math.com/03-16},
volume = {3},
year = {2009}
}
@article{Abraham2008,
archivePrefix = {arXiv},
arxivId = {arXiv:0808.2017v1},
author = {Abraham, Ittai and Bartal, Yair and Neiman, Ofer},
eprint = {arXiv:0808.2017v1},
file = {:home/tjhunter/Documents/Mendeley Desktop/Abraham, Bartal, Neiman\_2008\_Nearly tight low stretch spanning trees.pdf:pdf},
journal = {Foundations of Computer \ldots},
pages = {781--790},
title = {{Nearly tight low stretch spanning trees}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4691010},
year = {2008}
}
@article{Duchi2006,
author = {Duchi, John},
file = {:home/tjhunter/Documents/Mendeley Desktop/Duchi\_2006\_Projected Subgradient Methods for Learning Sparse Gaussians.pdf:pdf},
title = {{Projected Subgradient Methods for Learning Sparse Gaussians}},
year = {2006}
}
@article{Guruswami,
archivePrefix = {arXiv},
arxivId = {arXiv:1104.1732v4},
author = {Guruswami, Venkatesan and Sinop, Ali Kemal},
eprint = {arXiv:1104.1732v4},
file = {:home/tjhunter/Documents/Mendeley Desktop/Guruswami, Sinop\_Unknown\_Optimal Column-Based Low-Rank Matrix Reconstruction.pdf:pdf},
title = {{Optimal Column-Based Low-Rank Matrix Reconstruction}}
}
@article{Johnson,
archivePrefix = {arXiv},
arxivId = {arXiv:1112.6411v1},
author = {Johnson, Christopher C and Austin, U T and Jalali, Ali},
eprint = {arXiv:1112.6411v1},
file = {:home/tjhunter/Documents/Mendeley Desktop/Johnson, Austin, Jalali\_Unknown\_Greedy Methods.pdf:pdf},
title = {{Greedy Methods}}
}
@article{Link2012,
author = {Link, Citable and Choi, Myung Jin and Member, Student and Chandrasekaran, Venkat},
file = {:home/tjhunter/Documents/Mendeley Desktop/Link et al.\_2012\_Gaussian Multiresolution Models Exploiting Sparse Markov and Covariance Structure.pdf:pdf},
title = {{Gaussian Multiresolution Models : Exploiting Sparse Markov and Covariance Structure}},
year = {2012}
}
@techreport{Spielman2010,
abstract = {The Laplacian matrices of graphs are fundamental. In addition to facilitating the application of linear algebra to graph theory, they arise in many practical problems. In this talk we survey recent progress on the design of provably fast algorithms for solving linear equations in the Laplacian matrices of graphs. These algorithms motivate and rely upon fascinating primitives in graph theory, including low-stretch spanning trees, graph sparsifiers, ultra-sparsifiers, and local graph clustering. These are all connected by a definition of what it means for one graph to approximate another. While this definition is dictated by Numerical Linear Algebra, it proves useful and natural from a graph theoretic perspective.},
address = {Hyderabad, India},
author = {Spielman, Daniel A},
file = {:home/tjhunter/Documents/Mendeley Desktop/Spielman\_2010\_Algorithms , Graph Theory , and Linear Equations in Laplacian Matrices.pdf:pdf},
institution = {Proceedings of the International Congress of Mathematicians},
pages = {23},
title = {{Algorithms , Graph Theory , and Linear Equations in Laplacian Matrices}},
year = {2010}
}
@article{Vishwanathan2010,
author = {Vishwanathan, S V N and Schraudolph, Nicol N},
file = {:home/tjhunter/Documents/Mendeley Desktop/Vishwanathan, Schraudolph\_2010\_Graph Kernels.pdf:pdf},
pages = {1--45},
title = {{Graph Kernels}},
volume = {11},
year = {2010}
}
@article{,
file = {:home/tjhunter/Documents/Mendeley Desktop/Unknown\_Unknown\_No Title.pdf:pdf},
title = {{No Title}}
}
@article{Boyd2006,
author = {Boyd, Stephen},
file = {:home/tjhunter/Documents/Mendeley Desktop/Boyd\_2006\_Minimizing Effective Resistance of a Graph.pdf:pdf},
keywords = {Convex optimization,Networks and circuits,Systems on graphs},
pages = {1185--1196},
title = {{Minimizing Effective Resistance of a Graph}},
year = {2006}
}
@phdthesis{Gremban1996,
annote = {Look at chapter 4 for converting a SDD to a laplacian},
author = {Gremban, Keith D.},
file = {:home/tjhunter/Documents/Mendeley Desktop/Gremban\_1996\_Combinatorial Preconditioners for Sparse, Symmetric, Diagonally Dominant Linear Systems.gz:gz},
pages = {142},
school = {Carnegie Mellon University},
title = {{Combinatorial Preconditioners for Sparse, Symmetric, Diagonally Dominant Linear Systems}},
url = {www.cs.cmu.edu/~glmiller/Publications/GrembanPHD.ps.gz},
year = {1996}
}
@article{Hara2012,
archivePrefix = {arXiv},
arxivId = {arXiv:1203.0117v1},
author = {Hara, Satoshi and Washio, Takashi},
eprint = {arXiv:1203.0117v1},
file = {:home/tjhunter/Documents/Mendeley Desktop/Hara, Washio\_2012\_Learning a Common Substructure of Multiple Graphical Gaussian Models.pdf:pdf},
journal = {Arxiv preprint arXiv:1203.0117},
keywords = {alternating direction method of,augmented lagrangian,common substructure,dual,graphical gaussian model,multipliers},
title = {{Learning a Common Substructure of Multiple Graphical Gaussian Models}},
url = {http://arxiv.org/abs/1203.0117},
year = {2012}
}
@article{Hsieh2011,
author = {Hsieh, Cho-jui and Sustik, M and Dhillon, I and Ravikumar, P},
file = {:home/tjhunter/Documents/Mendeley Desktop//Hsieh et al.\_2011\_Sparse Inverse Covariance Matrix Estimation Using Quadratic Approximation.pdf:pdf},
journal = {Methods},
keywords = {cov},
mendeley-tags = {cov},
pages = {1--18},
title = {{Sparse Inverse Covariance Matrix Estimation Using Quadratic Approximation}},
url = {http://www.cs.utexas.edu/~cjhsieh/invcov.pdf},
year = {2011}
}
@article{Shental,
archivePrefix = {arXiv},
arxivId = {arXiv:0810.1736v1},
author = {Shental, Ori and Siegel, Paul H and Wolf, Jack K},
eprint = {arXiv:0810.1736v1},
file = {:home/tjhunter/Documents/Mendeley Desktop/Shental, Siegel, Wolf\_Unknown\_Gaussian Belief Propagation Solver for Systems of Linear Equations.pdf:pdf},
number = {x},
title = {{Gaussian Belief Propagation Solver for Systems of Linear Equations}}
}
@book{Zhang2005,
author = {Zhang, Fuzhen},
file = {:home/tjhunter/Documents/Mendeley Desktop/Zhang\_2005\_The Schur complement and its applications.pdf:pdf},
isbn = {0387242716},
keywords = {schur complement},
title = {{The Schur complement and its applications}},
url = {http://books.google.com/books?hl=en\&lr=\&id=EMEyg8NcuskC\&oi=fnd\&pg=PP12\&dq=THE+SCHUR+COMPLEMENT+AND+ITS+APPLICATIONS\&ots=98MulLugx2\&sig=Q4PsByld3VJqUIHJoiIUZP0QDzQ},
year = {2005}
}
@article{Aspremont2008,
archivePrefix = {arXiv},
arxivId = {arXiv:cs/0506023v1},
author = {Aspremont, Alexandre and Ghaoui, Laurent El},
eprint = {0506023v1},
file = {:home/tjhunter/Documents/Mendeley Desktop/Aspremont, Ghaoui\_2008\_Sparse Covariance Selection via Robust Maximum Likelihood Estimation.pdf:pdf},
pages = {1--8},
primaryClass = {arXiv:cs},
title = {{Sparse Covariance Selection via Robust Maximum Likelihood Estimation}},
year = {2008}
}
@article{Sparsifiers2009,
address = {New York, New York, USA},
author = {Batson, Joshua D. and Spielman, Daniel a. and Srivastava, Nikhil},
doi = {10.1145/1536414.1536451},
file = {:home/tjhunter/Documents/Mendeley Desktop/Batson, Spielman, Srivastava\_2009\_Twice-ramanujan sparsifiers.pdf:pdf},
isbn = {9781605585062},
journal = {Proceedings of the 41st annual ACM symposium on Symposium on theory of computing - STOC '09},
keywords = {any,expander graphs,grant ccf-0634957,spectral graph theory,the na-,this material is based,tional science foundation under,upon work supported by},
pages = {255},
publisher = {ACM Press},
title = {{Twice-ramanujan sparsifiers}},
url = {http://portal.acm.org/citation.cfm?doid=1536414.1536451},
year = {2009}
}
@article{Bickel2008,
author = {Bickel, Peter J. and Levina, Elizaveta},
doi = {10.1214/009053607000000758},
file = {:home/tjhunter/Documents/Mendeley Desktop/Bickel, Levina\_2008\_Regularized estimation of large covariance matrices.pdf:pdf},
issn = {0090-5364},
journal = {The Annals of Statistics},
month = feb,
number = {1},
pages = {199--227},
title = {{Regularized estimation of large covariance matrices}},
url = {http://projecteuclid.org/euclid.aos/1201877299},
volume = {36},
year = {2008}
}
@article{Chen2011,
author = {Chen, J},
file = {:home/tjhunter/Documents/Mendeley Desktop/Chen\_2011\_Computing f(A)b via Least Squares Polynomial Approximations.pdf:pdf},
journal = {SIAM Journal on Scientific Computing},
keywords = {1,65f30,65f35,65f50,a,ams subject classifications,b,gaussian process,introduction,is a matrix function,it is often necessary,least squares polynomials,matrix a and b,matrix function,product of,sampling,the form f,to compute a matrix-vector,well defined for the,where f},
pages = {1--28},
title = {{Computing f(A)b via Least Squares Polynomial Approximations}},
url = {http://www.mcs.anl.gov/~jiechen/pub/fAb.pdf},
year = {2011}
}
@article{Dahl2005,
author = {Dahl, Joachim and Roychowdhury, V and Vandenberghe, L},
file = {:home/tjhunter/Documents/Mendeley Desktop/Dahl, Roychowdhury, Vandenberghe\_2005\_Maximum likelihood estimation of gaussian graphical models numerical implementation and topology s.pdf:pdf},
journal = {Preprint},
pages = {1--29},
title = {{Maximum likelihood estimation of gaussian graphical models: numerical implementation and topology selection}},
url = {http://www.ee.ucla.edu/~vandenbe/publications/covsel1.pdf},
year = {2005}
}
@article{Kershaw1978,
author = {Kershaw, S},
file = {:home/tjhunter/Documents/Mendeley Desktop/Kershaw\_1978\_The incomplete Cholesky-Conjugate Solution of Systems.pdf:pdf},
pages = {43--65},
title = {{The incomplete Cholesky-Conjugate Solution of Systems}},
volume = {65},
year = {1978}
}
@article{Levin,
author = {Levin, Alex},
file = {:home/tjhunter/Documents/Mendeley Desktop/Levin\_Unknown\_Some Variants on Spectral Sparsification.pdf:pdf},
title = {{Some Variants on Spectral Sparsification}}
}
@article{Meeder,
author = {Meeder, Brendan},
file = {:home/tjhunter/Documents/Mendeley Desktop/Meeder\_Unknown\_Spectral Analysis for Billion-Scale Graphs Discoveries and Implementation.pdf:pdf},
title = {{Spectral Analysis for Billion-Scale Graphs : Discoveries and Implementation}}
}
@article{Nguyen,
address = {New York, New York, USA},
author = {Nguyen, Nam H. and Do, Thong T. and Tran, Trac D.},
doi = {10.1145/1536414.1536446},
file = {:home/tjhunter/Documents/Mendeley Desktop/Nguyen, Do, Tran\_2009\_A fast and efficient algorithm for low-rank approximation of a matrix.pdf:pdf},
isbn = {9781605585062},
journal = {Proceedings of the 41st annual ACM symposium on Symposium on theory of computing - STOC '09},
pages = {215},
publisher = {ACM Press},
title = {{A fast and efficient algorithm for low-rank approximation of a matrix}},
url = {http://portal.acm.org/citation.cfm?doid=1536414.1536446},
year = {2009}
}
@article{Seeger2010,
author = {Seeger, Matthias W},
file = {:home/tjhunter/Documents/Mendeley Desktop/Seeger\_2010\_Gaussian Covariance and Scalable Variational Inference.pdf:pdf},
title = {{Gaussian Covariance and Scalable Variational Inference}},
year = {2010}
}
@article{Smith2007,
author = {Smith, Richard L},
file = {:home/tjhunter/Documents/Mendeley Desktop/Smith\_2007\_Asymptotic properties of computationally efficient alternative estimators for a class of multivariate normal models.pdf:pdf},
journal = {Journal of Multivariate Analysis},
keywords = {approximate likelihood,autoregressive,computational,efficiency,massive data sets,processes on a lattice,spatial statistics,statistical efficiency analysis},
number = {May 2006},
pages = {1--31},
title = {{Asymptotic properties of computationally efficient alternative estimators for a class of multivariate normal models}},
url = {http://www.sciencedirect.com/science/article/pii/S0047259X06001333},
year = {2007}
}
@article{Spielmana,
author = {Spielman, Daniel A},
file = {:home/tjhunter/Documents/Mendeley Desktop/Spielman\_Unknown\_Spectral and Electrical Graph Theory.pdf:pdf},
title = {{Spectral and Electrical Graph Theory}}
}
@article{Sprechmann2012,
author = {Sprechmann, Pablo},
file = {:home/tjhunter/Documents/Mendeley Desktop/Sprechmann\_2012\_Learning Efficient Structured Sparse Models.pdf:pdf},
title = {{Learning Efficient Structured Sparse Models}},
year = {2012}
}
@article{Tsiligkaridis2012,
archivePrefix = {arXiv},
arxivId = {arXiv:1204.0585v1},
author = {Tsiligkaridis, Theodoros},
eprint = {arXiv:1204.0585v1},
file = {:home/tjhunter/Documents/Mendeley Desktop/Tsiligkaridis\_2012\_Convergence Properties of Kronecker Graphical Lasso Algorithms.pdf:pdf},
journal = {Arxiv preprint arXiv:1204.0585},
pages = {1--57},
title = {{Convergence Properties of Kronecker Graphical Lasso Algorithms}},
url = {http://arxiv.org/abs/1204.0585},
year = {2012}
}
@article{Vichik2011,
author = {Vichik, Sergey and Oshman, Yaakov},
file = {:home/tjhunter/Documents/Mendeley Desktop/Vichik, Oshman\_2011\_Optimal Covariance Selection for Estimation Using Graphical Models.pdf:pdf},
isbn = {9781457700798},
keywords = {Estimation,Machine learning,Reduced order modeling},
pages = {5049--5054},
title = {{Optimal Covariance Selection for Estimation Using Graphical Models}},
year = {2011}
}
@book{Wong2004,
author = {Wong, MN and Hickernell, FJ},
file = {:home/tjhunter/Documents/Mendeley Desktop/Wong, Hickernell\_2004\_Computing the trace of a function of a sparse matrix via Hadamard-like sampling.pdf:pdf},
keywords = {05b20,1,3,65c05,65f30,a,a number of applications,ams subject classifications,arises in,f,function of a large,gaussian quadrature,introduction,low discrepancy,matrix,monte carlo,quasi-monte carlo,specific examples,such as quantum chromodynamics,the trace of a,tr},
pages = {1--12},
title = {{Computing the trace of a function of a sparse matrix via Hadamard-like sampling}},
url = {ftp://ftp.math.hkbu.edu.hk/pub/techreport/math377.pdf},
year = {2004}
}
@article{Zouzias,
archivePrefix = {arXiv},
arxivId = {arXiv:1103.2793v2},
author = {Zouzias, Anastasios},
eprint = {arXiv:1103.2793v2},
file = {:home/tjhunter/Documents/Mendeley Desktop/Zouzias\_Unknown\_A Matrix Hyperbolic Cosine Algorithm and Applications.pdf:pdf},
keywords = {derandomization,probability,conditional expectatio},
title = {{A Matrix Hyperbolic Cosine Algorithm and Applications}}
}
